---
title: "Data acquisition and processing: Demultiplex & quality trim reads"
subtitle: "Central Valley Chinook Salmon"
author: "SJ O'Leary"
date: "`r Sys.Date()`"
output: tint::tintHtml
bibliography: ONC.bib
link-citations: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}

# load libraries and functions ====

# load libraries
library(tint)
library(knitr)
library(glue)
library(plyr)
library(magrittr)
library(tidyverse)


# load custom functions
source("scr/ggplot.R")
source("scr/xtrafunctions.R")


# OTHER OPTIONS ====

# set how numbers are printed
options(scipen=999)

# invalidate cache when the package version changes
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	cache.extra = packageVersion("tint"),
	tidy = FALSE
	# echo = FALSE
)

options(htmltools.dir.version = FALSE)

```

# Demultiplex sequence data

```{bash eval=FALSE}

# extract single end reads from concatenated files and assign to correct sample based on barcode.
process_radtags -f $datadir/BMAG002conc.fastq -i fastq -y gzfastq -b BMAG002.barcodes -o . --renz_1 sbfI -E phred33 -r --bestrad

```

`process_radtags` used to demultiplex samples for each set of samples (per library), files were then renamed to include LIB_ID (Prefix `ONC_`). For each library extraction script is in the `SEQ` subdirectory, resulting log-files for each library moved to `SEQ`-directory to assess quality.


# Quality control demultiplexed reads

Parse process radtags log file.

```{r echo=FALSE}

## import barcode information per sample and library ----
barcodes <- read_delim("data/SEQ/all.barcodes", delim = "\t")

## import process_radtags log files (all named process_radtags.LIB.log) ----

# directory with radtag logs
dir <- "data/SEQ"

# list all radtag logs
logs <- list.files(path = "data/SEQ", pattern = "process_radtags.*.log")

# create empty lists for results
l <- list()

t <- list()

# read in logs
for (i in 1:length(logs)){

  # path to log file
  f <- file.path(dir, logs[[i]])

  # get library name
  lib <- str_sub(logs[[i]], start = 17, end = -5)
  
  # get sample id and barcode
  demultiplex <- barcodes %>%
    filter(LIBRARY == lib) %>%
    select(-LIBRARY)

  # get number of samples
  n_samples <- as.numeric(nrow(demultiplex))
  
  # get information per individual
  l[[i]] <- read_table2(f,
                        skip = 12, n_max = n_samples,
                        col_names = c("BARCODE", "TOTAL_READS", "AMBIG_READS", "LQ_READS", "RETAINED")) %>%
        mutate(PROP_RETAINED = round(RETAINED/TOTAL_READS, digits = 3),
               LIBRARY = lib) %>%
        select(LIBRARY, BARCODE, PROP_RETAINED, TOTAL_READS, RETAINED, AMBIG_READS, LQ_READS) %>%
        left_join(demultiplex)
  
  # get information for whole library
  t[[i]] <- read_delim(f, skip = 5, n_max = 5, delim = "\t", 
                       col_names = c("PARAMETER", "VALUE")) %>%
    spread(key = PARAMETER, value = VALUE) %>%
    mutate(Library = lib,
           `Proportion retained` = round(`Retained Reads`/`Total Sequences`, digits = 3))

}

# create single data frame
radtagslog <- ldply(l, data.frame) %>%
  select(-LQ_READS)

write_delim(radtagslog, "results/all.radtags.log", delim = "\t")


# compare number of reads retained overall per librari
kable(
  ldply(t, data.frame) %>%
    arrange(Library) %>%
    mutate(Proportion.No.Barcode = round(`Barcode.Not.Found`/`Total.Sequences`, digits = 3),
           Proportion.No.Cutsite = round(`RAD.Cutsite.Not.Found`/`Total.Sequences`, digits = 3)) %>%
    select(Library, Total.Sequences, Retained.Reads, Proportion.retained, Proportion.No.Barcode, Proportion.No.Cutsite),
  caption = "Table : Comparison of total sequences and proportion of reads not retained due to barcodes and/or cut-sites not being found."
)

```

Compare demultiplexed reads per library.

```{r fig.cap="Distribution of total number of million reads per individuals and proportion of retained reads", fig.height=20, fig.width=6}

read_delim("results/all.radtags.log", delim = "\t") %>%
  mutate(MILL_READS = TOTAL_READS/1000000) %>%
  select(LIBRARY, BARCODE, PROP_RETAINED, MILL_READS) %>%
  gather(key = STAT, value = READS, 3:4) %>%
  ggplot(aes(x = READS)) +
  geom_histogram(color = "black", fill = "darkorange") +
  labs(x = "reads") +
  facet_grid(LIBRARY ~ STAT, scales = "free") +
  theme_standard

```

# Quality trim

## Remove low quality individuals

To cut down on computational power individuals with very low number of reads can be removed. Identify low quality individuals with <250,000 reads and <25% of reads retained.

```{r fig.cap="Figure : Overall distribution of million reads retained per individual", fig.width=5, fig.height=4}

read_delim("results/all.radtags.log", delim = "\t") %>%
  mutate(MILL_READS = TOTAL_READS/1000000) %>%
  ggplot(aes(x = MILL_READS)) +
  geom_histogram(binwidth = 1, color = "black", fill = "darkorange") +
  labs(x = "Million reads retained", y = "No. individuals") +
  theme_standard

lq_ind <- read_delim("results/all.radtags.log", delim = "\t") %>%
  filter(RETAINED < 250000 | PROP_RETAINED < 0.25)

```

Write bash script to delete `fastq` files of low quality individuals from data set.

```{r eval=FALSE}

seq_dir <- "$HOME/CHINOOK/data/SEQ/"

command <- "rm"

SEQ <- lq_ind %>%
  unite(FILE, LIBRARY, LIB_ID, sep = "/") %>%
  select(FILE) %>%
  mutate(temp = ".*",
         dir = seq_dir) %>%
  unite(SEQ, dir, FILE, temp, sep = "") %>%
  mutate(COMMAND = command) %>%
  select(COMMAND, SEQ)

write.table(SEQ, "scr/rm_LQind_ONC.sh",
            col.names = FALSE, quote = FALSE, row.names = FALSE)

```

Remove LQ individuals.

```{bash eval=FALSE}

chmod 755 ./scr/rm_LQind_ONC.sh

./scr/rm_LQind_ONC.sh

```


## Quality trim data

PCR and sequencing can result in technical artifacts resulting in low quality reads. For example, Illumina sequences produce sequences of lower quality in later cycles resulting in low quality base calls on the 3' end of sequences that need to be removed and partial adapter sequences may remain within the sequenced reads.

The `dDocent` pipeline wraps `fastp` [@Chen2018] to quality trim reads and detect and remove remaining adapter sequences. Reads are trimmed using a sliding window approach where bases are dropped if the mean quality in a base drops below a set threshold value. 

**Parameters used:**

* `--cut_by_quality5` 20
* `--cut_by_quality3` 20
* `--cut_window_size` 5
* `--cut_mean_quality` 15
* `-q` 15
* `-u` 50

Run `dDocent` in each sequence folder to quality trim reads (use `SLURM` file to queue on hpcc).

```{bash eval=FALSE}

# navigate to starting directory
cd $HOME/CHINOOK/data/SEQ/

for i in BMAG*; do

    cd cd $HOME/CHINOOK/data/SEQ/$i

    ## PREP FILES

    # copy of configuration file
    cp cd $HOME/CHINOOK/scr/trim.config .

    # load modules
    module purge
    module load Anaconda2/4.2.0

    ## RUN dDOCENT

    # open bioconda environment
    source activate /mnt/home/olearys1/bin/miniconda3/envs/ddocent_env

    # run dDocent to quality trim & map reads to reference genome
    dDocent trim_map.config

    # close bioconda environment
    source deactivate

done

```

