---
title: "Supplementary Material II"
subtitle: "Every cog and wheel: Unraveling biocomplexity at the genomic and phenotypic level in a population complex of Chinook salmon."
author: "Shannon J. O’Leary, Tasha Q. Thompson, Mariah H. Meek"
output: 
  tint::tintHtml:
    number_sections: true
    toc: true
    toc_depth: 2
bibliography: ONC.bib
link-citations: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}

# load libraries
library(tufte)
library(tint)
library(knitr)

library(glue)
library(plyr)
library(magrittr)
library(tidyverse)

library(coin)
library(UpSetR)

library(vcfR)

library(adegenet)
library(hierfstat)
library(pegas)
library(radiator)
library(assigner)
library(poppr)
library(vegan)


# load custom functions
source("scr/xtrafunctions.R")
source("scr/ggplot.R")
source("scr/genind.R")
source("scr/PCA.R")
source("scr/DAPC.R")

# OTHER OPTIONS ====

# set how numbers are printed
options(scipen=999)

# invalidate cache when the package version changes
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	cache.extra = packageVersion("tint"),
	cache = TRUE,
	tidy = FALSE,
	echo = FALSE
)
options(htmltools.dir.version = FALSE)

# SET LEVELS AND COLORS FOR GROUPS ====

# run types
run_levels <- c("Fall",
                "Late-Fall",
                "Winter",
                "Spring")

run_col <- c("#182f7e", # Fall | blue
             "#87c3fa", # Late-Fall | red
             "#dcd71e", # Winter | gold
             "#bc8111") # Spring | green

# basins
basin <- c("SAC",
           "SJO")


# tributaries
tributaries <- c("USR", # Sacramento
                 "COL", # Sacramento
                 "MIL", # Sacramento
                 "DER", # Sacramento
                 "BUT", # Sacramento
                 "FRH", # Sacramento
                 "NIM", # Sacramento
                 "MKH", # Sacramento
                 "STN", # San Juaquin
                 "TOU", # San Juaquin
                 "MRH", # San Juaquin
                 "MER") # San Juaquin       

trib_col <- c("#375623",    # USR
              "#70ad47",    # COL
              "#51ed21",    # MIL
              "#00c4bb",    # DER
              "#347C98",    # BUT
              "#87c3fa",    # FRH
              "#0247FE",    # NIM
              "#7008a0",    # MKH
              "#f200ff",    # STN
              "#FE2712",    # TOU
              "darkorange", # MRH
              "gold")       # MER

# tributaries within runs
trib_runs <- c("F_COL",
               "F_MIL",
               "F_DER",
               "F_BUT",
               "F_FRH",
               "F_NIM",
               "F_MKH",
               "F_STN",
               "F_TOU",
               "F_MRH",
               "F_MER",
               "L_USR",
               "W_USR",
               "S_MIL",
               "S_DER",
               "S_BUT",
               "S_FRH") # 7 individuals

trib_run_col <- c("#70ad47",    # F_COL
                  "#51ed21",    # F_MIL
                  "#00c4bb",    # F_DER
                  "#347C98",    # F_BUT
                  "#87c3fa",    # F_FRH
                  "#0247FE",    # F_NIM
                  "#7008a0",    # F_MKH
                  "#f200ff",    # F_STN
                  "#FE2712",    # F_TOU
                  "darkorange", # F_MRH
                  "gold",       # F_MER
                  "grey75",     # L_USR
                  "grey75",     # W_USR
                  "#51ed21",    # S_MIL
                  "#00c4bb",    # S_DER
                  "#347C98",    # S_BUT
                  "#87c3fa")    # S_FRH


col_nine <- c("#44546a", "#7008a0", "darkorange",
              "#ffbf00", "#4473c4", "#70ad47",
              "#c00000",  "#375623", "#5b9bd5")


# LOAD & FORMAT DATA SET ====

# create genind object ----
removeInd <- c("ONC-BMAG020-F080158MKH",
               "ONC-BMAG021-F080159MKH",
               "ONC-BMAG001-F020091USR",
               "ONC-BMAG001-F020093USR",
               "ONC-BMAG001-F020137BTC",
               "ONC-BMAG001-F020177BTC",
               "ONC-BMAG001-L030007BTC",
               "ONC-BMAG001-L030015BTC",
               "ONC-BMAG001-L001839COL",
               "ONC-BMAG001-L001919COL",
               "ONC-BMAG001-L000001BUT")


gen <- read.genepop(file = "data/POPGEN/ONC_haplot_run_genepop.gen",
                    ncode = 3L, quiet = FALSE)

gen <- gen.ind.rem.Ind(gen, removeInd)


SampleInfo <- read_delim("data/POPGEN/Sample_Info.txt", delim = "\t") %>%
  separate(LIB_ID, into = c("SP", "LIB", "SAMPLE_ID"),
           sep = "_", remove = TRUE, extra = "merge") %>%
  unite(LIB_ID, SP, LIB, SAMPLE_ID, sep = "-", remove = FALSE) %>%
  select(-SP, -INDV)
# format strata
strata <- as.data.frame(indNames(gen)) %>%
  rename(LIB_ID = `indNames(gen)`) %>%
  left_join(SampleInfo) %>%
  unite(RUN_LOC, RUN, LOCATION, sep = "_", remove = FALSE) %>%
  mutate(OVERALL = "ALL",
         RUN = case_when(RUN == "F" ~ "Fall",
                         RUN == "S" ~ "Spring",
                         RUN == "L" ~ "Late-Fall",
                         RUN == "W" ~ "Winter"),
         SOURCE = ifelse(LOCATION %in% c("COL", "FRH", "NIM", "MRH"), "HATCHERY", "WILD"),
         BASIN = ifelse(LOCATION %in% c("STN", "TOU", "MRH", "MER"), "SJO", "SAC"),
         RUN = ordered(RUN, levels = run_levels),
         LOCATION = ordered(LOCATION, levels = tributaries),
         RUN_LOC = ordered(RUN_LOC, levels = trib_runs),
         BASIN = ordered(BASIN, levels = basin)) %>%
  select(LIB, LIB_ID, SAMPLE_ID, YEAR, SOURCE, RUN, LOCATION, RUN_LOC, BASIN, OVERALL)

strata(gen) <- strata

# define populations using defined stratification
setPop(gen) <- ~RUN


# create genind objects for Fall and Spring individuals ----

gen_runs <- seppop(gen)

# fall individuals
gen_fall <- gen_runs[["Fall"]]
setPop(gen_fall) <- ~LOCATION

# spring individuals
gen_spring <- gen_runs[["Spring"]]
setPop(gen_spring) <- ~LOCATION

run_counts <- strata %>%
    count(RUN_LOC)

# set seed for random processes
set.seed(42)

```

# Genotyping

`r margin_note("Reads were mapped to the Christensen 2018 chinook genome and SNPs were called using freebayes. Filtered data set was haplotyped using rad_haplotyper. Fst-outlier were identified using FDIST method implemented in Arlequin and bayescan.")`

```{r}

# data sets
writeLines("\nFULL DATA SET: all SNP-containing loci/all individuals grouped by run type.")
gen


kable(
  strata %>%
    group_by(RUN, LOCATION) %>%
    count() %>%
    ungroup() %>%
    pivot_wider(names_from = RUN, values_from = n) %>%
    mutate(Fall = as.character(Fall),
           `Late-Fall` = as.character(`Late-Fall`),
           Winter = as.character(Winter),
           Spring = as.character(Spring)) %>%
    replace(is.na(.), "-"),
  caption = "Number of samples per tributary and run type."
)

```

*For details on bioinformatics on genotyping the data set see Supplementary Material I*


# Assessment of population structure and differentiation

Population structure was explored using two methods, a clustering analysis based on genetic similarity and an assessment of population differentiation among individuals grouped *a priori* based on run type and tributary. 

## PCA

Reduce the data's dimensionality using a principle component analysis and project genotypes into two dimensional space visualize sample's distances.

```{r echo=TRUE, fig.cap="Principal Component Analysis. Color and shape of each data point indicates run type of that individual."}

# create matrix with centered/scaled allele frequencies
# will also replace missing data
X <- scaleGen(gen, NA.method = "mean")

# perform PCA/retain top 3 PCs
PCA <- dudi.pca(X, center = FALSE, scale = FALSE,
                scannf = FALSE, nf = 10)

# extract Eigenvalues of each PC & calculate % variance explained by each PC
eig <- eigenvalues(PCA)

# # plot %variance explained by of top 25 PCs
# plot.eigen.variance(eig)

# Individuals' contribution to PCs/calculate Loading per individual and PC
PC_ind <- PC.ind(PCA)

# join individuals' contribution to PC with strata
PC_ind <- left_join(PC_ind, strata)

```

PC1 (2.5% of variation) separates Winter run individuals as being clearly distinct. Spring individuals cluster directly adjacent to Fall. PC2 (1.1% of variation) has a tight cluster of Late-Fall and Fall run individuals with Spring run clustering in a more spread out fashion. Spring Feather River Hatchery individuals cluster on the outskirts of the Fall cluster with Fall Feather River wild individuals.

```{r fig.cap="Principal Component Analysis. Color of each data point indicates tributary of that individual. Shape of data point indicates run type."}

ggplot(PC_ind, aes(x = Axis1, y = Axis2, 
                   fill = RUN_LOC,
                   shape = RUN)) +
  geom_point(size = 4) +
  scale_shape_manual(name = "run",
                     values = c(21, 22, 23, 24)) +
  scale_fill_manual(name = "tributary",
                    values = trib_run_col) +
  labs(x = paste("PC1:", round(eig[1, 3], digits = 1), "%"), y = paste("PC2:", round(eig[2, 3], digits = 1), "%")) +
  theme_standard +
  theme(legend.position = "bottom",
        legend.box = "vertical") +
  guides(fill = guide_legend(order = 1,
                             override.aes = list(shape = 21),
                             ncol = 4),
         shape = guide_legend(order = 2))

```


## k-mean clustering

Individuals were clustered into K = 2 – 10 groups using k-means clustering based on the PCA-transformed genotype matrix (i.e. no assumptions regarding Hardy-Weinberg or linkage disequilibrium) followed by a discriminant analysis of principle components (DAPC) to determine the membership probabilities of each sample to each inferred cluster as implemented in `adegenet` [@Jombart2010]. During DAPC, the genotype matrix is first PCA-transformed, then samples are partitioned into a within- and between-group component to maximize discrimination between groups using linear discriminant analysis, and finally, the membership probability of each sample to each cluster is calculated. To ensure sufficient variance was retained to discriminate among groups but not overfit the data, the optimum number of principle components to retain was determined using a stratified cross-validation of DAPC. 
 
Use k-means clustering to identify clusters based on genetic similarity (data transformed using PCA). For clustering it is appropriate to retain all PCs (all variance in the data set), as overfitting is not an issue.

```{r fig.cap="Figure S1: AIC for data clustered into K = 1 - 40 groups using k-means clustering.", fig.height=4, fig.width=7}

# k-means clustering
grp_AIC <- find.clusters.genind(gen, n.pca = 500, method = "kmeans",
                            stat = "AIC", choose.n.clust = FALSE, criterion = "min",
                            max.n.clust = 40)


Kstat <- as.data.frame(grp_AIC$Kstat) %>%
  rownames_to_column("K") %>%
  separate(K, c("temp", "K"), sep = "=") %>%
  mutate(K = as.numeric(K)) %>%
  rename(AIC = `grp_AIC$Kstat`) %>%
  select(K, AIC)

ggplot(Kstat, aes(x = K, y = AIC)) +
  geom_line() +
  geom_point(shape = 21, color = "black", fill = "darkorange", size = 3) +
  labs(x = "number of clusters K", y = "AIC") +
  theme_standard

```

AIC is minimized for `r names(grp_AIC$stat)`.

Perform stratified cross-validation of DAPC using a range of retained PCs, while keeping the number of discriminant functions fixed for K = 2 - 10 to determine the most appropriate number of principle components to retain sufficient variance to discriminate but not overfit the data.

```{r cache=TRUE, echo=TRUE}

## define minimum and maximum K to cluster for ----
min_K <- 2

max_K <- 10

# number of repetitions for x-validation
n_rep <- 30

# range of values to loop over
range <- min_K:max_K

## loop over values for K ----

# list for cross validation plots
xVal_plots <- list()

# data frame for optimum PCs
opt_PC <- data.frame(matrix(ncol = 4, nrow = 0)) %>%
    rename(k_clust = X1,
           optPC = X2,
           variance = X3,
           mean_opt_success = X4)

# list for membership plots
memb_plots <- list()


# run loop
for (k in range){

    # set value for K
    k_clust <- k

    # cluster
    grp <- find.clusters.genind(gen, n.pca = 500, n.clust = k_clust, method = "kmeans")

    # scale allele frq/missing data replaced with mean
    X <- scaleGen(gen, NA.method = "mean")

    xval <- xvalDapc(X, grp$grp,
                     n.pca.max = 400, training.set = 0.9,
                     result = "groupMean", center = TRUE, scale = FALSE,
                     n.pca = NULL, n.rep = n_rep, xval.plot = FALSE)

    # extract assignment success for each xVal step
    PCs <- data.frame(N_PCs = xval[["Cross-Validation Results"]]$n.pca,
                      PROP_SUCCESS = xval[["Cross-Validation Results"]]$success)

    # create crossvalidation plot
    xVal_plots[[k_clust]] <- ggplot(PCs, aes(x = N_PCs, y = PROP_SUCCESS)) +
      stat_density2d(aes(fill = ..density..^0.25),
                     geom = "tile", contour = FALSE, n = 200) +   
      geom_point() +
      scale_fill_continuous(low = "white", high = "dodgerblue4") +
      scale_y_continuous(limits = c(0, 1)) +
      labs(title = glue("Cross validation K = {k_clust}"),
           x = "retained PCs", y = "assignment success") +
      theme_standard +
      theme(legend.position = "none")


    # optimum number of PCs to retain
    retain <- as.numeric(xval$`Number of PCs Achieving Highest Mean Success`)

    variance <- round(xval[["DAPC"]]$var*100, digits = 2)

    opt <- PCs %>%
      filter(N_PCs == retain)

    df <- as.data.frame(x = k_clust) %>%
      mutate(optPC = retain,
             variance = variance,
             mean_opt_success = round(mean(opt$PROP_SUCCESS), digits = 2))

    opt_PC <- opt_PC %>%
        bind_rows(df)

    # extract membership assignment probabilities
    grp_membership <- as.data.frame(xval[["DAPC"]]$posterior) %>%
      rownames_to_column("LIB_ID") %>%
      gather(key = GRP, value = MEMBSHIP, 2:(k_clust+1)) %>%
      left_join(strata) %>%
      unite(RUN_LOC, RUN, LOCATION, sep = "_", remove = FALSE) %>%
      arrange(RUN_LOC, LIB_ID) %>%
      mutate(LIB_ID = factor(LIB_ID, levels = unique(LIB_ID)))

    path <- as.character(glue("results/runs_K{k}.grp.membership"))

    write_delim(grp_membership, path, delim = "\t")

    # create membership plot
    memb_plots[[k_clust]] <- ggplot(grp_membership,
                                    aes(x = LIB_ID, y = MEMBSHIP, fill = GRP, color = GRP)) +
      geom_bar(stat = "identity") +
      facet_grid(. ~ RUN_LOC, scales = "free", space = "free") +
      scale_fill_manual(values = col_nine) +
      scale_color_manual(values = col_nine) +
      labs(x = "INDV", y = "memb. prob") +
      theme_standard +
      theme(axis.text.x = element_blank(),
        strip.text.x = element_text(size = 6, color = "black"),
        strip.text.y = element_text(size = 6, color = "black"),
        legend.position = "none")

}

write_delim(opt_PC, "results/kmeans_all-loci.optPCs", delim = "\t")

```

Retaining too few PCs may result in important variance not being retained and therefore not informing the clustering analysis, while retaining too many PCs results in overfitting, i.e. assignment success decreases.

```{r fig.cap="Proportion of test individuals correctly assigned to their cluster of origin based on number of retained PCs for K = 2 - 9.", fig.height=15, fig.width=15}

multiplot(xVal_plots[[2]], xVal_plots[[3]], xVal_plots[[4]],
          xVal_plots[[5]], xVal_plots[[6]], xVal_plots[[7]],
          xVal_plots[[8]], xVal_plots[[9]], xVal_plots[[10]],
          cols = 3)

kable(
    opt_PC %>%
        arrange(desc(mean_opt_success)),
    caption = "Table S1: The optimum number of principle components, %-variance retained and the mean optimum assignment succes for K = 2 - 10 clusters."
    )

```

Genetic data is scaled and centered, then transformed using a PCA. Retained PCs are then transmitted to a linear discriminant analysis.

Calculate membership probability of each individual to per cluster.

```{r fig.cap="Membership probability of each individual to clusters identified using k-means hierarchical clustering (equiavalent to Figure 2 in manuscript).", fig.height=30, fig.width=9}

multiplot(memb_plots[[2]], memb_plots[[3]], memb_plots[[4]],
          memb_plots[[5]], memb_plots[[6]], memb_plots[[7]],
          memb_plots[[8]],
          cols = 1)

```

Tributaries are grouped within runs by tributary from north to south as `r knitr::combine_words(unique(grp_membership$RUN_LOC))` (individual panels).


## F-statistics

Weir & Cockerham’s unbiased estimator of FST [@Weir1984] was used to calculate population differentiation among individuals grouped *a priori* by run type within tributary. 

To test for genetic heterogeneity in the data set, global FST was calculated across all groups.

```{r eval=FALSE, echo=TRUE}

# group genetic data for comparison
setPop(gen) <- ~RUN_LOC

pop <- popNames(gen)

# calculate Fst
tidy <- tidy_genomic_data(data = gen, filename = NULL, parallel = 65)

fst <- assigner::fst_WC84(data = tidy,
                          pop.levels = pop,
                          holdout.samples = NULL,
                          pairwise = TRUE,
                          ci = TRUE,
                          iteration.ci = 1000,
                          quantiles.ci = c(0.025, 0.975),
                          digits = 9,
                          verbose = TRUE)

# write results
write_delim(fst$fst.overall, "results/trib_allLoc.globalfst.ci", delim = "\t")

write_delim(fst[["fst.ranked"]], "results/trib_ranked.perlocus.fst", delim = "\t")

write_delim(fst[["fis.markers"]], "results/trib_perlocus.fis", delim = "\t")

write_delim(fst$pairwise.fst, "results/trib_allLoc.fst.ci", delim = "\t")

write_delim(fst$sigma.loc, "results/trib_perlocus.sigma", delim = "\t")

write_delim(fst$fis.markers, "trib_perlocus.fis", delim = "\t")

write_delim(fst$fis.overall, "results/trib_allLoc.fis", delim = "\t")

```

**Significant heterogeneity** was detected among individuals grouped by run/tributary. Significance was determined using 95% confidence intervals around each estimate generated by re-sampling loci 1,000 times using `assigner` [@Gosselin2016].

```{r}

# CIs
kable(
  read_delim("results/trib_allLoc.globalfst.ci", delim = "\t"),
  caption = "Global Fst and 95% CI for individuals grouped by run type."
)

```

Pairwise FST was calculated as a *post hoc* test for pairwise differences among groups. Significance was determined using 95% confidence intervals around each estimate generated by re-sampling loci 1,000 times.

```{r fig.cap="Figure S2: Pairwise Fst of individuals grouped by run/tributary. Fst-values denoted with * have lower CI > 0", fig.width = 8, fig.height = 8}

fst <- read_delim("results/trib_allLoc.fst.ci", delim = "\t") %>%
    mutate(POP1 = ordered(POP1, levels = trib_runs),
           POP2 = ordered(POP2, levels = trib_runs))

# table with comparisons
kable(
    fst %>%
      separate(POP1, into = c("RUN1", "TRIB1"), sep = "_", remove = FALSE) %>%
      separate(POP2, into = c("RUN2", "TRIB2"), sep = "_", remove = FALSE) %>%
      unite(COMP, RUN1, RUN2, sep = "-") %>%
      select(POP1, POP2, COMP, N_MARKERS, FST, CI_LOW, CI_HIGH) %>%
      mutate(COMP = ordered(COMP, levels = c("F-F", "L-L", "W-W", "S-S",
                                             "F-L", "F-W", "F-S",
                                             "L-W","W-L", "L-S", "S-L", "W-S"))) %>%
      arrange(COMP, desc(FST)),
    digits = 3,
    caption = "Table S2: Pairwise Fst among runs basins.")

# prep for plotting
tmp <- fst %>%
    rename(tmp1 = POP1,
           tmp2 = POP2) %>%
    mutate(POP1 = tmp2,
           POP2 = tmp1) %>%
        select(POP1, POP2, N_MARKERS, FST, CI_LOW, CI_HIGH) %>%       
    bind_rows(fst) %>%
    mutate(sign = case_when(CI_LOW > 0 ~ glue("{round(FST, digits = 3)}*"),
                            CI_LOW == 0 ~ as.character(round(FST, digits = 3))))

# plot comparisons
ggplot(tmp, aes(x = POP1, y = POP2, fill = FST)) +
    geom_tile(color = "black") +
    geom_text(aes(label = sign), size = 2) +
    scale_fill_viridis_c(option = "viridis", begin = 0, end = 1, direction = -1) +
    labs(x = " ", y = " ") +
    theme_standard +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5))

```


# Assessment of genomic diversity

For all measures of genetic diversity comparisons were made for individuals grouped by run type within each tributary, with wild and hatchery individuals treated as separate groups even if they were sampled in the same tributary. Sample sizes among run/tributary groups are comparable with most in the range of 20 - 30, though only seven Feather River Spring individuals are present.

The following parameters are compared:

* Heterozygosity
    + observed heterozygosity Ho
    + expected heterozygosity Hs
    + inbreeding coefficient Fis

* Allele diversity
    + Allelic richness (allele counts and rarefied allele counts)
    + Evenness

* Sequence-based parameters
    + Nucleotide diversity ($\pi$)
    + Tajima's $D$
    
For each parameter, significant heterogeneity among groups was determined using a **Friedman's test**, which implements a repeated block design (alleles observed per locus present in each sample). Next, significance of pairwise comparisons was tested using a **Wilcoxon signed rank test**; p-values were adjusted assuming a FDR of 0.05. The use of the signed rank test gives "direction" to the test of significance, due to the block design, i.e. pairwise comparisons show that loci will consistently be lower (higher) across individuals as opposed to a test that does not account for the fact that the same blocks/loci are being observed (e.g. a t-test).

For Tajima's D, additionally we generated a genome-wide null distribution of Tajima's $D$ for a set of neutral loci assuming mutation drift-equilibrium reflecting the composition of the haplotyped empirical data set consisting of the same number of loci with same distribution of segregating sites by simulating loci under coalescence using `MS` [@Hudson2002] to compare to the empirical data set.

Results of tests of significance for comparisons are presented as a heatmap indicating the test statistic of pairwise comparisons and printed p-values, significantly different comparisons (P < 0.05) is presented. Finally, the distribution of values across loci for individuals grouped by run or run/tributary are presented as boxplots and a table with summary statistics.

* Patterns of unique diversity
    + fixed loci
    + singletons
    + loci only variable in one group (private polymorphisms)
    + true private alleles

To compare whether identified loci are randomly distributed across chromosomes, null distributions were generated by shuffling chromosome designations across loci 1,000 times to determine whether the observed values fall outside the null distribution.

## Calculate measures of genetic diversity based on allele frequency and heterozygosity

```{r eval=FALSE, echo=TRUE}

# define groups to analyze ====
setPop(gen) <- ~RUN_LOC

gen_grp <- seppop(gen)

gen_grp[["ALL"]] <- gen

# calculate diversity stats ====
loc_stats <- list()

for (p in names(gen_grp)) {

locA <- locus_table(gen_grp[[p]], index = "shannon") %>%
  as.data.frame() %>%
  rownames_to_column("LOCUS")

locB <- locus_table(gen_grp[[p]], index = "simpson") %>%
  as.data.frame() %>%
  rownames_to_column("LOCUS")

temp <- left_join(locA, locB)

locC <- locus_table(gen_grp[[p]], index = "invsimpson") %>%
  as.data.frame() %>%
  rownames_to_column("LOCUS")

loc_stats[[p]] <- left_join(temp, locC)

}

loc_stats <- ldply(loc_stats, data.frame) %>%
  select(-Hexp) %>%
  rename(GRP = `.id`,
         SIMPSON_IDX = `X1.D`,
         N_ALLELES = allele,
         SHANNON_IDX = H,
         STODD_TAYLOR_IDX = G,
         EVENNESS = Evenness)

# calculate genetic diversity stats (heterozygosity-based) ====
loc_stats_2 <- list()

for (p in names(gen_grp)) {

dat <- hierfstat:::.genind2hierfstat(gen_grp[[p]])
stats <- basic.stats(dat)

loc_stats_2[[p]] <- stats$perloc %>%
  rownames_to_column("LOCUS")

}

# combine into single data frame ====
loc_stats_2 <- ldply(loc_stats_2, data.frame) %>%
  rename(GRP = `.id`)

loc_stats <- left_join(loc_stats, loc_stats_2) %>%
  select(GRP, LOCUS, N_ALLELES, EVENNESS, Ho, Hs, Ht, Fis, SHANNON_IDX, SIMPSON_IDX, STODD_TAYLOR_IDX) %>%
  filter(LOCUS != "mean")

loc_stats[is.na(loc_stats)] <- NA

write_delim(loc_stats, "results/gendiv.locstats", delim = "\t")

```


## Observed heterozygosity

The observed heterozygosity (**Ho**) is measured as the proportion of heterozygote genotypes per locus [@Nei1987].


**Compare distribution of observed heterozygosity within and among runs**

`r margin_note("Test of significant differences among runs using Friedman's test.")`

```{r}

het <- read_delim("results/gendiv.locstats", delim = "\t") %>%
  select(GRP, LOCUS, Ho) %>%
  filter(GRP %in% trib_runs) %>%
  separate(GRP, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE) %>%
  mutate(GRP = ordered(GRP, levels = trib_runs))

# remove loci with Na values
rm <- het %>%
  filter(is.na(Ho))

temp <- het %>%
  filter(!LOCUS %in% rm$LOCUS)

friedman.test(Ho ~ GRP | LOCUS, data = temp)

```

Test for significant pairwise differences between tributaries within runs using Wilcoxon signed rank test.

```{r echo=TRUE}

# remove loci with Na values
rm <- het %>%
  filter(is.na(Ho))

het <- het %>%
  filter(!LOCUS %in% rm$LOCUS)

# groups to compare
comp <- as.character(unique(het$GRP))

# pairs of comparisons
pairs <- expand.grid(comp, comp) %>%
  filter(!Var1 == Var2) %>%
  rownames_to_column("PAIR") %>%
  split(.$PAIR) %>%
  purrr::map(function(x){
    x %>%
      select(-PAIR) %>%
      gather(key = temp, value = GRP, 1:2) %>%
      select(-temp)
  })

# empty data frame for results
results <- setNames(data.frame(matrix(ncol = 4, nrow = 0)), 
                    c("pop1", "pop2", "stat", "p.value")) %>%
  mutate(pop1 = as.character(pop1),
         pop2 = as.character(pop2),
         stat = as.numeric(stat),
         p.value = as.numeric(p.value))

n <- as.numeric(length(pairs))

# loop over pairs
for(i in 1:length(pairs)){

  p <- i

  pair <- pairs[[p]]$GRP

  temp <- het %>%
    filter(GRP %in% pair) %>%
    mutate(GRP = ordered(GRP, levels = pair),
         LOCUS = as.factor(LOCUS)) %>%
  droplevels()

  wilcox <- wilcoxsign_test(Ho ~ GRP | LOCUS,
                data = temp,
                zero.method = "Pratt")

  df <- data.frame("pop1" = pair[1],
                   "pop2" = pair[2],
                   "stat" = as.numeric(wilcox@statistic@teststatistic),
                   "p-value" = as.numeric(pvalue(wilcox)))

  results <- bind_rows(results, df)

}

results <- results %>%
  mutate(pop1 = ordered(pop1, levels = trib_runs),
         pop2 = ordered(pop2, levels = trib_runs))

write_delim(results, "results/obshet_run_trib.wilcox", delim = "\t")

```

Identify pairwise significantly different distribution between run/trib groups.

```{r fig.cap="Results pairwise comparisons of observed heterozygosity among tributaries within runs using Wilcoxon signed rank test.", fig.height=9, fig.width=7, echo=FALSE}

ggplot(results, aes(x = pop1, y = pop2, fill = stat)) +
  geom_tile(color = "black") +
  geom_text(aes(label = round(p.value*100, 1)), size = 2.5, color = "white") +
  scale_fill_viridis_c() +
  coord_fixed(ratio = 1) +
  labs(x = "", y = "") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Compare distributions.

```{r fig.cap="Distribution of observed heterozygosity of individuals grouped by tributary within each run.", fig.height=7, fig.width=9}

ggplot(het, aes(x = GRP, y = Ho, color = RUN, group = GRP)) +
  geom_boxplot() +
  labs(x = "", y = "observed heterozygosity Ho") +
  scale_color_manual(values = run_col) +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# ggsave("results/fig_obs-het.svg", 
#        dpi = 300,
#        height = 1600,
#        width = 1300,
#        units = "px")

kable(
  results %>%
    mutate(stat = round(stat, digits = 4),
           p.value = round(p.value, digits = 4),
           p_adj = round(p.adjust(p.value, method = "BH"), digits = 4)) %>%
    filter(stat > 0 & p_adj < 0.05) %>%
    arrange(desc(stat)),
  caption = "Significantly different pairwise comparisons of observed heterozygosity across loci for individuals grouped by tributaries within runs."
)

mean <- het %>%
    group_by(GRP) %>%
    summarize(mean = mean(Ho),
              sd = sd(Ho),
              median = median(Ho),
              Q1 = quantile(Ho, 0.25),
              Q3 = quantile(Ho, 0.75))

kable(
    mean,
    digits = 4,
    caption = "Table S3: Mean, standard deviation, median, 25th, and 75th quartile of observed heterozygosity across loci for individuals grouped by run type & tributary."
    )

```


## Expected heterozygosity

Expected heterozygosity **Hs** is calculated as the proportion of heterozygous genotypes expected under Hardy-Weinberg equilibrium  [@Nei1987].

**Compare distribution of gene diversity within and among runs**

`r margin_note("Test of significant differences among runs using Friedman's test.")`

```{r}

het <- read_delim("results/gendiv.locstats", delim = "\t") %>%
  select(GRP, LOCUS, Hs) %>%
  filter(GRP %in% trib_runs) %>%
  separate(GRP, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE) %>%
  mutate(GRP = ordered(GRP, levels = trib_runs))

# remove loci with Na values
rm <- het %>%
  filter(is.na(Hs))

temp <- het %>%
  filter(!LOCUS %in% rm$LOCUS)

friedman.test(Hs ~ GRP | LOCUS, data = temp)

```

Test for significant pairwise differences between tributaries within runs using Wilcoxon signed rank test.

```{r fig.cap="Results pairwise comparisons of expected heterozygosity among tributaries within runs using Wilcoxon signed rank test.", fig.height=9, fig.width=7}

# remove loci with Na values
rm <- het %>%
  filter(is.na(Hs))

het <- het %>%
  filter(!LOCUS %in% rm$LOCUS)

# groups to compare
comp <- as.character(unique(het$GRP))

# pairs of comparisons
pairs <- expand.grid(comp, comp) %>%
  filter(!Var1 == Var2) %>%
  rownames_to_column("PAIR") %>%
  split(.$PAIR) %>%
  purrr::map(function(x){
    x %>%
      select(-PAIR) %>%
      gather(key = temp, value = GRP, 1:2) %>%
      select(-temp)
  })

# empty data frame for results
results <- setNames(data.frame(matrix(ncol = 4, nrow = 0)), 
                    c("pop1", "pop2", "stat", "p.value")) %>%
  mutate(pop1 = as.character(pop1),
         pop2 = as.character(pop2),
         stat = as.numeric(stat),
         p.value = as.numeric(p.value))

n <- as.numeric(length(pairs))

# loop over pairs
for(i in 1:length(pairs)){

  p <- i

  pair <- pairs[[p]]$GRP

  temp <- het %>%
    filter(GRP %in% pair) %>%
    mutate(GRP = ordered(GRP, levels = pair),
         LOCUS = as.factor(LOCUS)) %>%
  droplevels()

  wilcox <- wilcoxsign_test(Hs ~ GRP | LOCUS,
                data = temp,
                zero.method = "Pratt")

  df <- data.frame("pop1" = pair[1],
                   "pop2" = pair[2],
                   "stat" = as.numeric(wilcox@statistic@teststatistic),
                   "p-value" = as.numeric(pvalue(wilcox)))

  results <- bind_rows(results, df)

}

results <- results %>%
  mutate(pop1 = ordered(pop1, levels = trib_runs),
         pop2 = ordered(pop2, levels = trib_runs))

write_delim(results, "results/obshet_run_trib.wilcox", delim = "\t")

ggplot(results, aes(x = pop1, y = pop2, fill = stat)) +
  geom_tile(color = "black") +
  geom_text(aes(label = round(p.value*100, 1)), size = 2.5, color = "white") +
  scale_fill_viridis_c() +
  coord_fixed(ratio = 1) +
  labs(x = "", y = "") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Compare distributions across groups.

```{r fig.cap="Distribution of expected heterozygosity per locus for individuals grouped by tributary within each run.", fig.height=7, fig.width=7}

ggplot(het, aes(x = GRP, y = Hs, color = RUN, group = GRP)) +
  geom_boxplot() +
  labs(x = "", y = "expected heterozygosity Hs") +
  scale_color_manual(values = run_col) +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# ggsave("results/fig_exp-het.svg", 
#        dpi = 300,
#        height = 1600,
#        width = 1300,
#        units = "px")

kable(
  results %>%
    mutate(stat = round(stat, digits = 4),
           p.value = round(p.value, digits = 4),
           p_adj = round(p.adjust(p.value, method = "BH"), digits = 4)) %>%
    filter(stat > 0 & p_adj < 0.05) %>%
    arrange(desc(stat)),
  caption = "Significance of pairwise comparisons of expected heterozygosity for individuals grouped by tributaries within runs."
)

mean <- het %>%
    group_by(GRP) %>%
    summarize(mean = mean(Hs),
              sd = sd(Hs),
              median = median(Hs),
              Q1 = quantile(Hs, 0.25),
              Q3 = quantile(Hs, 0.75))

kable(
    mean,
    caption = "Table S4: Mean, standard deviation, median, 25th, and 75th quartile of observed heterozygosity per locus for individuals grouped by run type & tributary.",
    digits = 4
    )

```

## Inbreeding coefficient (Fis)

The inbreeding coefficient **Fis** is calculated as 1-Ho/He [@Weir1984] and indicates heterozygote deficiencies compared to expectations under Hardy-Weinberg Equilibrium, i.e. it is a measure of deviation from panmixia at local scales.


**Compare distribution of heterozygosity deficiency (Fis) within and among runs**

`r margin_note("Test of significant differences among runs using Friedman's test.")`

```{r}

het <- read_delim("results/gendiv.locstats", delim = "\t") %>%
  select(GRP, LOCUS, Fis) %>%
  filter(GRP %in% trib_runs) %>%
  separate(GRP, into = c("RUN", "TRIBUTARY"), 
           sep = "_", remove = FALSE) %>%
  mutate(GRP = ordered(GRP, levels = trib_runs))

# remove loci with Na values
rm <- het %>%
  filter(is.na(Fis))

temp <- het %>%
  filter(!LOCUS %in% rm$LOCUS)

friedman.test(Fis ~ GRP | LOCUS, data = temp)

```

Test for significant pairwise differences between tributaries within runs using Wilcoxon signed rank test.

```{r fig.cap="Results pairwise comparisons of Fis among tributaries within runs using Wilcoxon signed rank test.", fig.height=9, fig.width=7}

# remove loci with Na values
rm <- het %>%
  filter(is.na(Fis))

het <- het %>%
  filter(!LOCUS %in% rm$LOCUS)

# groups to compare
comp <- as.character(unique(het$GRP))

# pairs of comparisons
pairs <- expand.grid(comp, comp) %>%
  filter(!Var1 == Var2) %>%
  rownames_to_column("PAIR") %>%
  split(.$PAIR) %>%
  purrr::map(function(x){
    x %>%
      select(-PAIR) %>%
      gather(key = temp, value = GRP, 1:2) %>%
      select(-temp)
  })

# empty data frame for results
results <- setNames(data.frame(matrix(ncol = 4, nrow = 0)), 
                    c("pop1", "pop2", "stat", "p.value")) %>%
  mutate(pop1 = as.character(pop1),
         pop2 = as.character(pop2),
         stat = as.numeric(stat),
         p.value = as.numeric(p.value))

n <- as.numeric(length(pairs))

# loop over pairs
for(i in 1:length(pairs)){

  p <- i

  pair <- pairs[[p]]$GRP

  temp <- het %>%
    filter(GRP %in% pair) %>%
    mutate(GRP = ordered(GRP, levels = pair),
         LOCUS = as.factor(LOCUS)) %>%
  droplevels()

  wilcox <- wilcoxsign_test(Fis ~ GRP | LOCUS,
                data = temp,
                zero.method = "Pratt")

  df <- data.frame("pop1" = pair[1],
                   "pop2" = pair[2],
                   "stat" = as.numeric(wilcox@statistic@teststatistic),
                   "p-value" = as.numeric(pvalue(wilcox)))

  results <- bind_rows(results, df)

}

results <- results %>%
  mutate(pop1 = ordered(pop1, levels = trib_runs),
         pop2 = ordered(pop2, levels = trib_runs))

write_delim(results, "results/fis_run_trib.wilcox", delim = "\t")

ggplot(results, aes(x = pop1, y = pop2, fill = stat)) +
  geom_tile(color = "black") +
  geom_text(aes(label = round(p.value*100, 1)), size = 2.5, color = "white") +
  scale_fill_viridis_c() +
  coord_fixed(ratio = 1) +
  labs(x = "", y = "") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Compare distributions across groups.

```{r fig.cap="Distribution of Fis per locus for individuals grouped by tributary within each run.", fig.height=7, fig.width=7}

ggplot(het, aes(x = GRP, y = Fis, color = RUN, group = GRP)) +
  geom_boxplot() +
  labs(x = "", y = "Fis") +
  scale_color_manual(values = run_col) +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# ggsave("results/fig_Fis.svg",
#        dpi = 300,
#        height = 1600,
#        width = 1300,
#        units = "px")

kable(
  results %>%
    mutate(stat = round(stat, digits = 4),
           p.value = round(p.value, digits = 4),
           p_adj = round(p.adjust(p.value, method = "BH"), digits = 4)) %>%
    filter(stat > 0 & p_adj < 0.05) %>%
    arrange(desc(stat)),
  caption = "Significance of pairwise comparisons of Fis for individuals grouped by tributaries within runs."
)

kable(
  results %>%
    mutate(stat = round(stat, digits = 4),
           p.value = round(p.value, digits = 4),
           p_adj = round(p.adjust(p.value, method = "BH"), digits = 4)) %>%
    filter(stat > 0 & p_adj > 0.05) %>%
    arrange(desc(stat)),
  caption = "Pairwise comparisons of Fis that are not significantly different for individuals grouped by tributaries within runs."
)

mean <- het %>%
    group_by(GRP) %>%
    summarize(mean = mean(Fis, na.rm = TRUE),
              sd = sd(Fis, na.rm = TRUE),
              median = median(Fis, na.rm = TRUE),
              Q1 = quantile(Fis, 0.25, na.rm = TRUE),
              Q3 = quantile(Fis, 0.75, na.rm = TRUE))

kable(
    mean,
    caption = "Table S5: Mean, standard deviation, median, 25th, and 75th quartile of Fis per locus for individuals grouped by run type & tributary.",
    digits = 4
    )

```


## Comparison of allelic richness

The number of alleles observed per locus is not independent from sample size, especially for small samples sizes; with an increasing number of individuals sampled an increasing number of alleles is expected to be identified as rare alleles are more likely to be observed only for larger sample sizes. Differences in sample size can be adjusted for using rarefaction, i.e. by determining the lowest sample size and then subsampling x individuals from each group and counting alleles and using the mean number as the allele count.


**Compare differences in rarefied allele counts among tributaries within runs**

Calculate allele count per locus corrected for differences in sample size using rarefaction.

```{r eval=FALSE, echo=TRUE}

# by tributary within run
setPop(gen) <- ~RUN_LOC

# calculate allele counts using rarefaction
dat <- genind2hierfstat(gen)

df <- allelic.richness(dat,
                       diploid = TRUE)

df <- as.data.frame(df$Ar) %>%
  rownames_to_column("LOCUS")

colnames(df) <- c("LOCUS", trib_runs)

write_delim(df, "results/trib_run_rarefied.allelecount", delim = "\t")

```

`r margin_note("Test of significant differences among runs using Friedman's test.")`

```{r}

ar <- read_delim("results/trib_run_rarefied.allelecount", delim = "\t") %>%
  gather(key = pop, value = AR, 2:18) %>%
  mutate(pop = ordered(pop, levels = trib_runs)) %>%
  separate(pop, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE)

friedman.test(AR ~ pop | LOCUS, data = ar)

```

Test for significant pairwise differences between tributaries within runs using Wilcoxon signed rank test.

```{r fig.cap="Significance of pairwise comparison of rarefied allele counts among runs using Wilcoxon signed rank test. Tile color indicates p-value, label is stat (indicates direction of difference); p-values were adjusted for multiple comparisons using Benjamini-Hochberg.", fig.height=9, fig.width=9}

# groups to compare
comp <- as.character(unique(ar$pop))

# pairs of comparisons
pairs <- expand.grid(comp, comp) %>%
  filter(!Var1 == Var2) %>%
  rownames_to_column("PAIR") %>%
  split(.$PAIR) %>%
  purrr::map(function(x){
    x %>%
      select(-PAIR) %>%
      gather(key = temp, value = GRP, 1:2) %>%
      select(-temp)
  })

# empty data frame for results
results <- setNames(data.frame(matrix(ncol = 4, nrow = 0)), 
                    c("pop1", "pop2", "stat", "p.value")) %>%
  mutate(pop1 = as.character(pop1),
         pop2 = as.character(pop2),
         stat = as.numeric(stat),
         p.value = as.numeric(p.value))

n <- as.numeric(length(pairs))

# loop over pairs
for(i in 1:length(pairs)){

  p <- i

  pair <- pairs[[p]]$GRP

  temp <- ar %>%
    filter(pop %in% pair) %>%
    mutate(pop = ordered(pop, levels=pair),
         LOCUS = as.factor(LOCUS)) %>%
  droplevels()

  wilcox <- wilcoxsign_test(AR ~ pop | LOCUS,
                data = temp,
                zero.method = "Pratt")

  df <- data.frame("pop1" = pair[1],
                   "pop2" = pair[2],
                   "stat" = as.numeric(wilcox@statistic@teststatistic),
                   "p-value" = as.numeric(pvalue(wilcox)))

  results <- bind_rows(results, df)

}


results <- results %>%
  mutate(pop1 = ordered(pop1, levels = trib_runs),
         pop2 = ordered(pop2, levels = trib_runs))

write_delim(results, "results/allelrich_trib_run.wilcox")

ggplot(results, aes(x = pop1, y = pop2, fill = stat)) +
  geom_tile(color = "black") +
  geom_text(aes(label = round(p.value, 2)), size = 2.5, color = "white") +
  scale_fill_viridis_c() +
  coord_fixed(ratio = 1) +
  labs(x = "", y = "") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Compare distributions of values.

```{r fig.cap="Distribution of rarefied allele counts per locus for individuals grouped by run type within tributaries.", fig.height=7, fig.width=9}

ggplot(ar, aes(x = pop, y = AR, color = RUN, group = pop)) +
  geom_boxplot() +
  scale_color_manual(values = run_col) +
  labs(x = "", y = "rarefied allele count") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# ggsave("results/fig_ar.svg", 
#        dpi = 300,
#        height = 1600,
#        width = 1300,
#        units = "px")

# summary stats
mean <- ar %>%
    group_by(pop) %>%
    summarize(mean = mean(AR),
              sd = sd(AR),
              median = median(AR),
              Q1 = quantile(AR, 0.25),
              Q3 = quantile(AR, 0.75))

kable(
  results %>%
    mutate(stat = round(stat, digits = 4),
           p.value = round(p.value, digits = 4),
           p_adj = round(p.adjust(p.value, method = "BH"), digits = 4)) %>%
    filter(stat > 0 & p_adj < 0.05) %>%
    arrange(desc(stat)),
  caption = "Significance of pairwise comparisons of allele counts per locus for individuals grouped by run type within tributaries."
)


kable(
    mean,
    caption = "Table S6: Mean, standard deviation, median, 25th, and 75th quartile of allelic richness across loci for individuals grouped by run type & tributary.",
    digits = 2
    )


```


## Evenness of allelic diversity

The **Evenness** of allelic diversity at a given locus is calculated as the ratio of the number of abundant genotypes to the number of rarer genotypes calculated using the ratio of `Stoddart & Tayolor index` (diversity index weighted for more abundant alleles) & `Shannon-Wiener index` (diversity index weighted for more rare alleles).


**Compare differences in evenness of allelic diversity among tributaries within runs**

`r margin_note("Test of significant differences among runs using Friedman's test.")`

```{r}

even <- read_delim("results/gendiv.locstats", delim = "\t") %>%
  select(GRP, LOCUS, EVENNESS) %>%
  filter(GRP %in% trib_runs) %>%
  separate(GRP, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE) %>%
  mutate(GRP = ordered(GRP, levels = trib_runs))

# remove loci with Na values
rm <- even %>%
    filter(is.na(EVENNESS))

temp <- even %>%
    filter(!LOCUS %in% rm$LOCUS)

friedman.test(EVENNESS ~ GRP | LOCUS, data = temp)

```

Test for significant pairwise differences between runs using Wilcoxon signed rank test.

```{r fig.cap="Significance of pairwise comparisons of evenness of allelic diversity per locus for individuals grouped by run type within tributaries using using Wilcoxon signed rank test. Tile color indicates stat (indicates direction of difference); p-values were adjusted for multiple comparisons using Benjamini-Hochberg.", fig.height=9, fig.width=9}

# remove loci with Na values
rm <- even %>%
  filter(is.na(EVENNESS))

even <- even %>%
  filter(!LOCUS %in% rm$LOCUS)

# groups to compare
comp <- as.character(unique(even$GRP))

# pairs of comparisons
pairs <- expand.grid(comp, comp) %>%
  filter(!Var1 == Var2) %>%
  rownames_to_column("PAIR") %>%
  split(.$PAIR) %>%
  purrr::map(function(x){
    x %>%
      select(-PAIR) %>%
      gather(key = temp, value = GRP, 1:2) %>%
      select(-temp)
  })

# empty data frame for results
results <- setNames(data.frame(matrix(ncol = 4, nrow = 0)), 
                    c("pop1", "pop2", "stat", "p.value")) %>%
  mutate(pop1 = as.character(pop1),
         pop2 = as.character(pop2),
         stat = as.numeric(stat),
         p.value = as.numeric(p.value))

n <- as.numeric(length(pairs))

# loop over pairs
for(p in 1:n){

  pair <- pairs[[p]]$GRP

  temp <- even %>%
    filter(GRP %in% pair) %>%
    mutate(GRP = ordered(GRP, levels = pair),
         LOCUS = as.factor(LOCUS)) %>%
  droplevels()

  wilcox <- wilcoxsign_test(EVENNESS ~ GRP | LOCUS,
                data = temp,
                zero.method = "Pratt")

  df <- data.frame("pop1" = pair[1],
                   "pop2" = pair[2],
                   "stat" = as.numeric(wilcox@statistic@teststatistic),
                   "p-value" = as.numeric(pvalue(wilcox)))

  results <- bind_rows(results, df)

}

results <- results %>%
  mutate(pop1 = ordered(pop1, levels = trib_runs),
         pop2 = ordered(pop2, levels = trib_runs))

write_delim(results, "results/evennes_trib_run.wilcox", delim = "\t")

ggplot(results, aes(x = pop1, y = pop2, fill = stat)) +
  geom_tile(color = "black") +
  geom_text(aes(label = round(p.value, 2)), size = 2.5, color = "white") +
  scale_fill_viridis_c() +
  coord_fixed(ratio = 1) +
  labs(x = "", y = "") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

kable(
  results %>%
    mutate(stat = round(stat, digits = 2),
           p.value = round(p.value, digits = 4),
           p_adj = round(p.adjust(p.value, method = "BH"), digits = 4)) %>%
    filter(stat > 0 & p_adj < 0.05) %>%
    arrange(desc(stat)),
  caption = "Significance of pairwise comparisons of evenness of allelic diversity across loci for individuals grouped by run type within tributaries."
)

```

Compare distributions of values.

```{r fig.cap="Distribution of evenness of allelic diversity per locus for individuals grouped by run type within tributaries.", fig.height=7, fig.width=9}

ggplot(even, aes(x = GRP, y = EVENNESS, color = RUN, GRP = GRP)) +
  geom_boxplot() +
  labs(x = "", y = "Evenness") +
  scale_color_manual(values = run_col) +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# ggsave("results/fig_evenness.svg", 
#        dpi = 300,
#        height = 1600,
#        width = 1300,
#        units = "px")

# summary stats
mean <- even %>%
    group_by(GRP) %>%
    summarize(mean = mean(EVENNESS, na.rm = TRUE),
              sd = sd(EVENNESS, na.rm = TRUE),
              median = median(EVENNESS, na.rm = TRUE),
              Q1 = quantile(EVENNESS, 0.25, na.rm = TRUE),
              Q3 = quantile(EVENNESS, 0.75, na.rm = TRUE))

kable(
    mean,
    caption = "Table S7: Mean, standard deviation, median, 25th, and 75th quartile of evenness of evenness per locus for individuals grouped by run type & tributary.",
    digits = 4
    )

```


## Nucleotide diversity $\pi$ (pairwise differences)

$\theta_{T}$ [@Nei1987], the **nucleotide diversity** ($\pi$) is calculated as the sum of the number of differences between pairs of haplotypes of a given locus, divided by the number of comparisons made. This parameter is biased towards alleles segregating at intermediate rates and will underestimate genetic diversity due to rare alleles.

Create a tidy data set of variant call information (position, alternate alleles) from filtered VCF file used to create haplotypes. Create a data frame of haplotype sequences in the data set(s) using reference contig sequences, VCF information, and `codes.out` file from `rad_haplotyper`.

```{r eval=FALSE, echo=TRUE}

# Read in the reference sequence
fa <- seqinr::read.fasta("data/REF/CHRIST2018/reference.fasta")

# create tibble with locus name and sequence
ref <- tibble::tibble(name = seqinr::getName(fa), seq = toupper(unlist(seqinr::getSequence(fa, as.string = TRUE))))

# Read the haplotype VCF file and put it in tidy format
vcf_tidy <- read.vcfR("data/POPGEN/ONC.haps.filtered.recode.vcf") %>%
    vcfR2tidy()

# Get the data frame with the positions
pos_tbl <- vcf_tidy$fix %>%
  filter(ALT %in% c("A", "T", "C", "G")) %>%
  unite(LOCUS, CHROM, POS, sep = "_", remove = FALSE)


# Make a data frame with all of the haplotype sequences from the 'codes.out' file from rad_haplotyper
hap_index <- read_tsv("data/HAPLOTYPING/codes.ONC.gen", col_names = FALSE) %>%
    filter(X1 %in% locNames(gen_obj)) %>%
    split(.$X1) %>%
    purrr::map(function(x) {
      codes <- str_split(x$X2, ",") %>%
        unlist()

      code_tbl <- tibble(locus = x$X1, code = codes) %>%
        separate(code, c("hap", "code"), sep = ":") %>%
        left_join(ref, by = c("locus" = "name"))

      pos <- pos_tbl %>%
        filter(CHROM == code_tbl$locus[1]) %>%
        pull(POS)

      for (i in 1:nrow(code_tbl)) {

        alleles <- str_split(code_tbl$hap[i], "") %>%
          unlist()

        replace <- tibble(pos = pos, allele = alleles)

        for (j in 1:nrow(replace)) {
          str_sub(code_tbl$seq[i], replace$pos[j], 1) <- replace$allele[j]
        }

      }

      code_tbl

    }) %>%
    bind_rows()

```

Calculate nucleotide diversity for individuals grouped by run type within each tributary.

```{r eval=FALSE, echo=TRUE}

# set pops
setPop(gen) <- ~RUN_LOC

# create tidy data set
gen_tidy <- gen %>%
  genind2df(oneColPerAll = TRUE) %>%
  rownames_to_column(var = "ind") %>%
  gather(allele, code, -pop, -ind) %>%
  separate(allele, c("locus", "allele"), sep = "\\.") %>%
  filter(pop %in% trib_runs) %>%
  droplevels()

# Calculate haplotype related stats
hap_div_tbl <- locNames(gen) %>%
  purrr::map(function(y) {

    # for each locus
    gen_tidy %>%
      filter(locus == y) %>%
      filter(!code == "NA") %>%
      left_join(hap_index, by = c("code", "locus")) %>%
      as.tibble() %>%
      arrange(factor(pop, levels = trib_runs)) %>%

      # for each population per locus
      split(.$pop) %>%
      purrr::map(function(x) {
        y <- do.call(rbind, strsplit(x$seq, ""))
        rownames(y) <- paste(x$ind, x$allele, sep = ".")

        # create DNAbin object for locus
        dna_bin <- as.DNAbin(y)                            

        # calculate Tajima's D and p-values
        taj_test <- tajima.test(dna_bin)

        # create table with results
        tibble(locus = x$locus[1],
               pop = x$pop[1],
               nuc_div = nuc.div(dna_bin)
               
      }) %>%
      bind_rows()
  }) %>%
    bind_rows()

write_delim(hap_div_tbl, "results/trib_run.hapdiv", delim = "\t")

```

`r margin_note("Test of significant differences among runs using Friedman's test. To get an unreplicated complete block design only loci variable in all locations were used for test of heterogeneity among groups.")`

```{r}

theta <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, nuc_div, seg_sites) %>%
  separate(pop, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE) %>%
  mutate(pop = ordered(pop, levels = trib_runs))

tmp <- theta %>%
  count(locus) %>%
  filter(n == 17)

tmp <- theta %>%
  filter(locus %in% tmp$locus)

friedman.test(nuc_div ~ pop | locus, data = tmp)

```

Test for significance of pairwise comparisons using Wilcoxon signed rank test.

```{r fig.cap="Pairwise comparison of levels of significant differences among individuals grouped by tributary and run type.", fig.height=7, fig.width=7}

# groups to compare
comp <- as.character(unique(theta$pop))

# pairs of comparisons
pairs <- expand.grid(comp, comp) %>%
  filter(!Var1 == Var2) %>%
  rownames_to_column("PAIR") %>%
  split(.$PAIR) %>%
  purrr::map(function(x){
    x %>%
      select(-PAIR) %>%
      gather(key = temp, value = pop, 1:2) %>%
      select(-temp)
  })

# empty data frame for results
results <- setNames(data.frame(matrix(ncol = 4, nrow = 0)), 
                    c("pop1", "pop2", "stat", "p.value")) %>%
  mutate(pop1 = as.character(pop1),
         pop2 = as.character(pop2),
         stat = as.numeric(stat),
         p.value = as.numeric(p.value))

n <- as.numeric(length(pairs))

# loop over pairs
for(p in 1:n){

  pair <- pairs[[p]]$pop

  temp <- tmp %>%
    filter(pop %in% pair) %>%
    mutate(pop = ordered(pop, levels = pair),
         locus = as.factor(locus)) %>%
  droplevels()

  wilcox <- wilcoxsign_test(nuc_div ~ pop | locus,
                data = temp,
                zero.method = "Pratt")

  df <- data.frame("pop1" = pair[1],
                   "pop2" = pair[2],
                   "stat" = as.numeric(wilcox@statistic@teststatistic),
                   "p-value" = as.numeric(pvalue(wilcox)))

  results <- bind_rows(results, df)

}

results <- results %>%
  mutate(pop1 = ordered(pop1, levels = trib_runs),
         pop2 = ordered(pop2, levels = trib_runs))

write_delim(results, "results/nuc_div_trib_run.wilcox", delim = "\t")


ggplot(results, aes(x = pop1, y = pop2, fill = stat)) +
  geom_tile(color = "black") +
  geom_text(aes(label = round(p.value, 2)), size = 2.5, color = "white") +
  scale_fill_viridis_c() +
  coord_fixed(ratio = 1) +
  labs(x = "", y = "") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Compare distribution of values.

```{r fig.cap="Distribution of nucleotide diversity across all loci for individuals grouped by tributary and runs", fig.height=7, fig.width=9}

ggplot(theta, aes(x = pop, y = nuc_div, color = RUN)) +
  geom_boxplot() +
  scale_color_manual(values = run_col) +
  labs(x = "", y = "nucleotide diversity") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# ggsave("results/fig_nuc-div.svg", 
#        dpi = 300,
#        height = 1600,
#        width = 1300,
#        units = "px")

kable(
  results %>%
    filter(stat > 0) %>%
    mutate(stat = round(stat, digits = 4),
           p.value = round(p.value, digits = 4),
           p_adj = round(p.adjust(p.value, method = "BH"), digits = 4)) %>%
    arrange(desc(stat)),
  caption = "Significance of pairwise comparisons of nucleotide diversity among runs within tributaries."
)

mean <- theta %>%
  group_by(pop) %>%
  summarize(mean = mean(nuc_div),
            std = sd(nuc_div),
            max = max(nuc_div),
            min = min(nuc_div)) %>%
  ungroup()

kable(
  mean,
  digits = 6,
  caption = "Table S8: Comparison of mean +/- standard deviation, minimum, and maximum values of the nucleotide diversity (pi) across loci among individuals grouped by run within tributary."
)

```


## Tajima's D

$\theta$ is the population-scaled mutation rate and can be estimated as $\hat{\theta}_T$ [@Nei1987], the number of pairwise differences (nucleotide diversity, $\pi$), while $\hat{\theta}_W$ is measured as the number of segregating sites [@Watterson1975].

Because $\hat{\theta}_T$ will underestimate the number of mutations that are rare in the population, Tajima's $D$ can be used to test the neutral mutation hypothesis: 

* Tajima's $D$ = 0 occurs when the observed variation is similar to the expected variation; this is generally interpreted as the population evolving as per mutation-drift equilibrium.
* A negative Tajima's $D$ occurs when the observed variation is less than expected and there are fewer haplotypes (lower heterozygosity) compared to the number of segregating sites. This occurs when a population expands after a bottleneck or for loci affected by or linked to loci affected by directed selection.
* A positive Tajima's $D$ occurs when the observed heterozygosity is higher than the expected and there are more haplotypes (more heterozygosity) compared to the expected value give the number of segregating sites. This occurs when a population declines or loci are affected by balancing selection.

### Pairwise comparison of Tajima's D across populations

`r margin_note("Test of significant differences among runs using Friedman's test. To get an unreplicated complete block design only loci variable (Tajima's D is able to be calculated) in all locations were used for test of heterogeneity among groups.")`

```{r}

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, tajima_d) %>%
  separate(pop, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE) %>%
  mutate(pop = ordered(pop, levels = trib_runs)) %>%
  filter(!is.na(tajima_d))

tmp <- taj %>%
  count(locus) %>%
  filter(n == 17)

tmp <- taj %>%
  filter(locus %in% tmp$locus)

friedman.test(tajima_d ~ pop | locus, data = tmp)

```

Test for significance of pairwise comparisons using Wilcoxon signed rank test.

```{r fig.cap="Pairwise comparison of levels of significant differences among individuals grouped by tributary and run type.", fig.height=7, fig.width=7}

# groups to compare
comp <- as.character(unique(taj$pop))

# pairs of comparisons
pairs <- expand.grid(comp, comp) %>%
  filter(!Var1 == Var2) %>%
  rownames_to_column("PAIR") %>%
  split(.$PAIR) %>%
  purrr::map(function(x){
    x %>%
      select(-PAIR) %>%
      gather(key = temp, value = pop, 1:2) %>%
      select(-temp)
  })

# empty data frame for results
results <- setNames(data.frame(matrix(ncol = 4, nrow = 0)), 
                    c("pop1", "pop2", "stat", "p.value")) %>%
  mutate(pop1 = as.character(pop1),
         pop2 = as.character(pop2),
         stat = as.numeric(stat),
         p.value = as.numeric(p.value))

n <- as.numeric(length(pairs))

# loop over pairs
for(p in 1:n){

  pair <- pairs[[p]]$pop

  temp <- tmp %>%
    filter(pop %in% pair) %>%
    mutate(pop = ordered(pop, levels = pair),
         locus = as.factor(locus)) %>%
  droplevels()

  wilcox <- wilcoxsign_test(tajima_d ~ pop | locus,
                data = temp,
                zero.method = "Pratt")

  df <- data.frame("pop1" = pair[1],
                   "pop2" = pair[2],
                   "stat" = as.numeric(wilcox@statistic@teststatistic),
                   "p-value" = as.numeric(pvalue(wilcox)))

  results <- bind_rows(results, df)

}

results <- results %>%
  mutate(pop1 = ordered(pop1, levels = trib_runs),
         pop2 = ordered(pop2, levels = trib_runs))

write_delim(results, "results/taj_trib_run.wilcox", delim = "\t")


ggplot(results, aes(x = pop1, y = pop2, fill = stat)) +
  geom_tile(color = "black") +
  geom_text(aes(label = round(p.value, 2)), size = 2.5, color = "white") +
  scale_fill_viridis_c() +
  coord_fixed(ratio = 1) +
  labs(x = "", y = "") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Compare distribution of values.

```{r fig.cap="Distribution of nucleotide diversity across all loci for individuals grouped by tributary and runs", fig.height=7, fig.width=9}

ggplot(taj, aes(x = pop, y = tajima_d, color = RUN)) +
  geom_boxplot() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values = run_col) +
  labs(x = "", y = "Tajima's D") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# ggsave("results/fig_taj.svg", 
#        dpi = 300,
#        height = 1600,
#        width = 1300,
#        units = "px")

kable(
  results %>%
    filter(stat > 0) %>%
    mutate(stat = round(stat, digits = 4),
           p.value = round(p.value, digits = 4),
           p_adj = round(p.adjust(p.value, method = "BH"), digits = 4)) %>%
    arrange(desc(stat)),
  caption = "Significance of pairwise comparisons of nucleotide diversity among runs within tributaries."
)

mean <- taj %>%
  group_by(pop) %>%
  summarize(mean = mean(tajima_d),
            std = sd(tajima_d),
            max = max(tajima_d),
            min = min(tajima_d)) %>%
  ungroup() %>%
  arrange(desc(mean))

kable(
  mean,
  digits = 6,
  caption = "Table S9: Comparison of mean +/- standard deviation, minimum, and maximum values of the Tajima's D across loci among individuals grouped by run within tributary."
)

```

### Comparison to simulated data set assuming mutation-drift equilibrium

Without detailed demographic information, it can be difficult to distinguish between an effect of selection, population expansion/decline and drift compared to demographics. Calculating a conventional p-value is problematic because you cannot describe the distribution of Tajimas $D$ independent of true $\theta$ value which is unknown.

Originally, Tajima proposed comparing the distribution to a beta distribution, however this has been shown to be too conservative. Instead, to identify whether the observed genome-wide distribution of Tajima's $D$ reflects the expected distribution under the neutral mutation hypothesis, we will generate a genome-wide null distribution of Tajima's $D$ for a set of neutral loci reflecting the composition of the haplotyped empirical data set consisting of the same number of loci with same distribution of segregating sites by simulating loci under coalescence using `MS` [@Hudson2002] to compare to the empirical data set.

#### F_COL

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_COL") %>% pull(n)`) F_COL run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 30 individuals (60 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=60

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind60_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind60")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_COL"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all <- list()

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_MIL 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_MIL") %>% pull(n)`) F_MIL run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 20 individuals (40 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=40

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind40_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind40")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_MIL"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_DER

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_DER") %>% pull(n)`) F_DER run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 15 individuals (30 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=30

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind30_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind30")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_DER"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_BUT 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_BUT") %>% pull(n)`) F_BUT run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 21 individuals (42 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=42

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind42_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind60")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_BUT"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_FRH 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_FRH") %>% pull(n)`) F_FRH run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 27 individuals (54 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=54

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind54_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind54")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_FRH"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

taj_all[[grp]] <- taj

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_NIM 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_NIM") %>% pull(n)`) F_NIM run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 30 individuals (60 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=60

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind60_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind60")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_NIM"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_MKH 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_MKH") %>% pull(n)`) F_MKH run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 28 individuals (56 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=56

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind56_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind56")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_MKH"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_STN 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_STN") %>% pull(n)`) F_STN run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 23 individuals (46 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=46

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind46_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind46")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_STN"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_TOU 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_TOU") %>% pull(n)`) F_TOU run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 30 individuals (60 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=60

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind60_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind60")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_TOU"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_MRH 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_MRH") %>% pull(n)`) F_MRH run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 15 individuals (30 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=30

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind30_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind30")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_MRH"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### F_MER 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "F_MER") %>% pull(n)`) F_MER run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 31 individuals (62 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=62

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind62_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind62")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "F_MER"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### L_USR 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "L_USR") %>% pull(n)`) L_USR run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 21 individuals (42 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=42

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind42_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind42")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "L_USR"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### W_USR 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "W_USR") %>% pull(n)`) W_USR run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 26 individuals (52 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=52

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind52_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind42")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "W_USR"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### S_MIL 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "S_MIL") %>% pull(n)`) S_MIL run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 16 individuals (32 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=32

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind32_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind32")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "S_MIL"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### S_DER 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "S_DER") %>% pull(n)`) S_DER run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 27 individuals (54 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=54

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind54_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind54")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "S_DER"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```


#### S_BUT 

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "S_BUT") %>% pull(n)`) S_BUT run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 19 individuals (38 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=38

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind38_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind38")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "S_BUT"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(!seg_sites == 0) %>%
  filter(pop == grp) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### S_FRH  

The maximum number of segregating sites per locus in the data set is `r max(theta$seg_sites)`, there are `r run_counts %>% filter(RUN_LOC == "S_FRH") %>% pull(n)`) S_FRH run individuals in the data set.

`r margin_note("Simulate 1000 independent replicates (loci) for 1 - 7 segregating sites under neutral model for 7 individuals (14 observations).")`

```{bash eval=FALSE, echo=TRUE}

# 2*number of individuals in data set
N=14

# number of loci to simulate
REP=1000

# simulate neutral loci
for i in {1..7}
do

  scr/MS/ms $N $REP -s $i | scr/MS/sample_stats > results/Ind14_Sites${i}_neut_Rep1000.stats

done

```

The `sample_stat` script distributed along side `MS` calculates summary statistics including Tajima's $D$ for simulated set of loci.

`r margin_note("Generate 100 simulated data sets based on empirical data set, by determining the number of loci with 1 ... x segregating sites and randomly drawing that number of loci from simulated data set (1,000 simulated loci per bin; draw with replacement) to generate null distribution consisting of the same number of loci with the same distribution of segregating sites per locus as the empirical data set.")`

```{r echo=TRUE}

# create a vector of stats files based on simulations
filenames <- list.files(path = "results/", pattern = "Ind14")

# create an empty list that will serve as a container to receive the incoming files
sim <-list()

# create a loop to read in your data
for (i in 1:length(filenames)){

  sim[[i]] <- read_delim(file.path("results", filenames[i]), delim = "\t",
                         col_names = c("t1", "pi",
                                       "t2", "seg_sites",
                                       "t3", "tajima_d",
                                       "t4", "thetaH",
                                       "t5", "H")) %>%
    select(pi, seg_sites, tajima_d, thetaH, H)

}

# add names
names(sim) <- filenames

# combine into dataframe
sim <- ldply(sim, data.frame) %>%
  rename(simulation = `.id`) %>%
  separate(simulation, into = c("temp", "t1"), sep = -6) %>%
  separate(temp, into = c("N_IND", "t2", "scenario", "N_REPS"), sep = "_") %>%
  mutate(N_REPS = as.numeric(str_extract(N_REPS, "[[:digit:]]+")),
         N_IND = as.numeric(str_extract(N_IND, "[[:digit:]]+"))) %>%
  select(-t1, -t2)

reps <- 100

# group to be compared
grp <- "S_FRH"

# get counts for number of segregating sites
emp <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites) %>%
  filter(pop == grp) %>%
  filter(!seg_sites == 0) %>%
  count(seg_sites)

# create null distributions
null_distributions <- list()

for (s in emp$seg_sites) {

      # determine number of loci with s segregating  sites
      t <- emp %>%
        filter(seg_sites == s)

      n_loci <- t$n

     # sample n_loci simulated loci (with replacement)
     null_distributions[[s]] <- sim %>%
        filter(seg_sites == s) %>%
        sample_n(size = n_loci, replace = TRUE)

}

null_distributions <- ldply(null_distributions, data.frame) %>%
    mutate(pop = grp)

taj <- read_delim("results/trib_run.hapdiv", delim = "\t") %>%
  select(locus, pop, seg_sites, tajima_d) %>%
  filter(!seg_sites == 0,
         pop == grp) %>%
  bind_rows(null_distributions) %>%
  mutate(scenario = ifelse(is.na(scenario), "empirical", scenario)) %>%
  select(-N_IND, -N_REPS, -pi, -thetaH, -H)

taj_all[[grp]] <- taj

```

Use K-S test statistic to identify simulated null distribution most similar to empirical data set (values closer to 0 indicate higher probability to have been draw from the same distribution).

```{r fig.cap="Cumulative distribution curves of empirical data set (black) to simulated data set (grey). The black dashed lines indicates expected value for Tajima's D under equilibrium assuming a beta distribution (the median should intersect at 0).", fig.width=8, fig.height=5}

ggplot(taj, aes(x = tajima_d, group = scenario, color = scenario)) +
   stat_ecdf(size = 1) +
   geom_hline(yintercept = 0.5, color = "black", linetype = "dashed") +
   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    scale_color_manual(values = c("black", "grey")) +
   labs(x = "Tajima's D", y = "cumulative distribution") +
   theme_standard

x <- taj %>%
  filter(scenario == "empirical") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

y <- taj %>%
  filter(scenario == "neut") %>%
  select(tajima_d) %>%
  unlist() %>%
  as.numeric()

# test F/L
ks.test(x, y, alternative = "two.sided")

```

#### Comparison across all trib/run populations

Let's compare the null and empirical distributions across all data sets.

```{r fig.cap="Comparison of neutral and empirical distributions of Tajima's D for each run in each tributary.",fig.height=10, fig.width=10}

taj_all <- ldply(taj_all, data.frame) %>%
  mutate(pop = ordered(pop, levels = trib_runs))

ggplot(taj_all, aes(x = pop, y = tajima_d, 
                    color = scenario)) +
  scale_color_manual(values = c("black", "grey65")) +
  geom_boxplot() +
  labs(x = "", y = "Tajima's D") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

kable(
  taj_all %>%
    group_by(pop, scenario) %>%
    summarize(mean = mean(tajima_d),
              median = median(tajima_d),
              Q1 = quantile(tajima_d, 0.25),
              Q3 = quantile(tajima_d, 0.75)),
  caption = "Table S10: Mean, median, 25% and 75% quantiles Tajima's D for empirical and simulated data sets.",
  digits = 4
)


kable(
  taj_all %>%
    group_by(pop, scenario) %>%
    summarize(mean = mean(tajima_d)) %>%
    pivot_wider(names_from = "scenario", values_from = "mean") %>%
    mutate(difference = empirical-neut) %>%
    arrange(desc(difference)),
  caption = "Difference in mean Tajima's D between empirical and simulated data sets.",
  digits = 4
)


kable(
  taj_all %>%
    group_by(pop, scenario) %>%
    summarize(median = median(tajima_d)) %>%
    pivot_wider(names_from = "scenario", values_from = "median") %>%
    mutate(difference = empirical-neut) %>%
    arrange(desc(difference)),
  caption = "Difference in mean Tajima's D between empirical and simulated data sets.",
  digits = 4
)


```

Typically the mean is lower than the median but we are more interested in genome-wide patterns so the median is more informative.

The median lower in the empirical data sets compared to the simulated data set under mutation drift equilibrium in the following populations. 

* F_COL (hatchery)
* F_MIL
* F_BUT
* F_NIM (hatchery)
* F_MRH (merced river hatchery)
* F_MER (merced river)


Very small to no difference in the medians for the following populations:

* F_DER
* F_FRH (hatchery)
* S_MIL


The mean and median are higher in the empirical data sets compared to the simulated data set under mutation drift equilibrium in the following populations

* F_MKH (hatchery)
* F_STN
* F_TOU 
* L_USR
* W_USR (positive mean value; biggest difference in medians)
* S_DER
* S_BUT (positive mean value; second biggest difference in medians)
* S_FRH (median essentially the same)


## Fixed loci

**Fixed loci** are loci that are not polymorphic for a given set of individuals, i.e. all individuals are homozygous for the same allele. The **global allele frequency/counts** is the allele frequency or count for a given locus across all individuals.

Differences in sample size may create bias for this comparison, as sample sizes that are (too) low can result in not all alleles being present in a population being sampled in a sufficiently representative manner, which can lead loci to appear fixed even though they do have rare alleles that were simply not sampled. Sample sizes are quite variable across run types, but for individuals grouped by run type withing tributaries, the sample sizes do become much more comparable.


**Comparison of fixed loci within tributaries within runs**

Identify number of fixed loci within individuals grouped by tributary and run type.

```{r}

tidy_ar <- read_delim("results/trib_run_rarefied.allelecount", delim = "\t") %>%
  gather(key = GRP, AR, 2:18) %>%
  mutate(GRP = ordered(GRP, levels = trib_runs))

kable(
  tidy_ar %>%
    filter(AR == 1) %>%
    select(GRP, LOCUS, AR) %>%
    count(GRP),
  format_args = list(big.mark = ","),
  caption = "Number of fixed alleles for individuals of each tributary grouped by run type (using rarefied allele counts)."
)

```

Identify loci that are fixed in more than on set of individuals grouped by tributary and run type: The set size (horizontal green bars) indicates the total number of loci fixed in a given location, the intersection size (vertical orange bars) indicates the number of loci fixed only in a single location (single blue dot) or in two, three, or four locations (indicated by blue dots connected by line).

```{r fig.height=8, fig.width=13, fig.fullwidth=TRUE}

# split into list
fixed <- tidy_ar %>%
  filter(AR == 1) %>%
  select(GRP, LOCUS, AR) %>%
  dlply("GRP", identity)

# create vector
listInput <- list()

for (l in names(fixed)){

listInput[[l]] <- fixed[[l]]$LOCUS

}

upset(fromList(listInput),
      sets = trib_runs,
      keep.order = TRUE,
      matrix.color = "darkblue",
      main.bar.color = "darkorange",
      sets.bar.color = "darkgreen",
      shade.color = "grey95",
      shade.alpha = 1,
      matrix.dot.alpha = 1,
      text.scale = 1)

```

Calculate allelic richness across all individuals in a data set.

```{r echo=TRUE, eval=FALSE}

# calculate global allelic richness
setPop(gen) <- ~OVERALL

# calculate allele counts using rarefaction
dat <- genind2hierfstat(gen)

df <- allelic.richness(dat,
                       diploid = TRUE)

ar <- as.data.frame(df$Ar) %>%
  rownames_to_column("LOCUS") %>%
  select(-3)

colnames(ar) <- c("LOCUS", "OVERALL")

write_delim(ar, "results/rarefied.allelecount", delim = "\t")

```


Determine the global rarefied allele counts for loci that are fixed in at least one group.

```{r fig.cap="Distribution of global rarefied allele counts for loci fixed across individuals grouped by tributary within runs.", fig.height=7, fig.width=9}

all <- read_delim("results/rarefied.allelecount", delim = "\t") %>%
  select(LOCUS, OVERALL) %>%
  rename(TOTAL_ALLELES = OVERALL)

fixed <- tidy_ar %>%
  filter(AR == 1) %>%
  left_join(all) %>%
  separate(GRP, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE) %>%
  mutate(GRP = ordered(GRP, levels = trib_runs))

ggplot(fixed, aes(x = GRP, y = TOTAL_ALLELES, color = RUN, group = GRP)) +
  geom_boxplot() +
  scale_color_manual(values = run_col) +
  scale_y_continuous(limits = c(0, 6)) +
  labs(x = "", y = "global diversity of fixed alleles") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

mean <- fixed %>%
    group_by(GRP) %>%
    summarize(mean = mean(TOTAL_ALLELES),
              median = median(TOTAL_ALLELES),
              Q1 = quantile(TOTAL_ALLELES, 0.25),
              Q3 = quantile(TOTAL_ALLELES, 0.75))

kable(
    mean,
    digits = 2,
    caption = "Table S11: Comparison of mean, median, 25th and 75th quantile of global diversity at fixed loci for individuals grouped by run/tributary."
    )

```

Compare the distribution of fixed loci across the genome.

```{r fig.width=20, fig.height=45, fig.fullwidth=TRUE}

# chromosome and chromosome number
chrom <- read_delim("data/REF/CHRIST2018/chrom.contigs", delim = " ") %>%
  mutate(CHROM = str_trim(CHROM))

# position of contigs on chromosomes/scaffolds
contigs <- read_delim("data/REF/CHRIST2018/map_intervals.bed", delim = "\t",
                      col_names = c("CHROM", "chromStart", "chromEnd", "LOCUS")) %>%
  left_join(chrom)

fixed <- fixed %>%
  left_join(contigs) %>%
  filter(!is.na(CHROMOSOME))

all_loci <- tidy_ar %>%
  left_join(contigs) %>%
  filter(!is.na(CHROMOSOME))

n_chrom <- contigs %>%
    filter(!is.na(CHROMOSOME)) %>%
    count(CHROMOSOME) %>%
    rename(total = n)

pattern <- fixed %>%
        count(GRP, CHROMOSOME) %>%
        left_join(n_chrom) %>%
        mutate(percent = (n/total)*100)

n <- pattern %>%
    select(CHROMOSOME, total, GRP, n) %>%
    spread(key = GRP, value = n)

frq <- pattern %>%
    select(CHROMOSOME, total, GRP, percent) %>%
    spread(key = GRP, value = percent)

# print table
kable(
    frq %>%
    rename(CHR = CHROMOSOME),
    digits = 1,
    caption = "Proportion of loci on chromosome of fixed loci per chromosome for individuals grouped by run type."
    )

```

Determine the null distribution of the proportion of loci expected to be fixed per chromosome if fixed loci are randomly distributed among chromosomes. Maintain the total number of loci fixed for a run/tributary group and the total number of loci per chromosome in the data by shuffling chromosome designations across loci. Then calculate the proportion of loci fixed on a chromosome for each run/tributary group and determining if the observed value falls is higher than the 5th and lower than the 95th percentile; determine significance as observed value lying outside observed distribution.

```{r echo=TRUE}

obs <- tidy_ar %>%
   mutate(FIXED = ifelse(AR == 1, TRUE, FALSE)) %>%
   mutate(GRP = ordered(GRP, levels = trib_runs)) %>%
   left_join(contigs) %>%
    filter(!is.na(CHROMOSOME)) %>%
    select(GRP, LOCUS, FIXED, CHROMOSOME)

reps <- 1000

sim <- list()

for(i in 1:reps){

    sim[[i]] <- obs %>%
        group_by(GRP) %>%
        mutate(SIM = sample(CHROMOSOME, replace = FALSE)) %>%
        ungroup() %>%
        filter(FIXED == TRUE) %>%
        count(GRP, SIM) %>%
        left_join(n_chrom, by = c("SIM" = "CHROMOSOME")) %>%
        mutate(percent = (n/total)*100)
}

null_dist <- ldply(sim, data.frame) %>%
    group_by(GRP, SIM) %>%
    summarize(min = min(percent),
              max = max(percent)) %>%
    ungroup() %>%
    rename(CHROMOSOME = SIM) %>%
    left_join(pattern) %>%
    select(GRP, CHROMOSOME, total, n, percent, min, max) %>%
    mutate(sign = ifelse(percent > min & percent < max, "expected", "significant"))

```

Compare observed and simulated distributions.

```{r}

kable(
    null_dist %>%
        filter(sign == "significant") %>%
        select(-sign),
    digits = 2,
    caption = "Table S12: Chromosomes with significantly higher/lower than expected (outside simulated null distribution) number of fixed loci for each run/tributary group."
    )


kable(
    pattern %>%
        group_by(GRP) %>%
        summarize(mean = mean(percent),
                  sd = sd(percent),
                  min = min(percent),
                  max = max(percent)),
    digits = 2,
    caption = "Table S13: Mean +/- sd, minimum, and maximum percent of loci per chromosome that are fixed across a group of individuals with the same run type for a given tributary."
    )

```


## Singletons

**Singletons** are alleles that only occur in a single individual. This could be a locus that is only variable in one individual or a locus that has multiple alleles though one (or more) of those alleles are extremely rare occurring in only one individual.

```{r echo=TRUE}

# group all individuals in single group
setPop(gen) <- ~OVERALL

# calculate basic stats
dat <- genind2hierfstat(gen)
stats <- basic.stats(dat)

# extract & format allele frequencies per locus into single df
f <- stats$pop.freq

freq <- list()

for(l in names(f)){

freq[[l]] <- as.data.frame(f[[l]]) %>%
  filter(Var2 == 1) %>%
  rename(ALLELE = x,
         FRQ = Freq) %>%
  select(ALLELE, FRQ)

}

freq <- ldply(freq, data.frame) %>%
  rename(LOCUS = `.id`)

# identify singletons
Nind <- length(indNames(gen))

min <- round(1/(2*Nind), digits = 4)

singletons <- freq %>%
  filter(FRQ <= min) %>%
  mutate(ALLELE = as.integer(ALLELE))

```

Total number of alleles across all loci in the data set is `r nrow(freq)`, the total number of singletons is `r nrow(singletons)` (`r round(nrow(singletons)/nrow(freq)*100, digits = 1)`% of loci) exhibit at least one singleton.

```{r}

kable(
    singletons %>%
        count(LOCUS) %>%
        count(n) %>%
        rename(loci = nn,
               singletons = n),
    caption = "Number of loci with x singletons."
    )

```

Compare distribution of loci with singletons across the genome to random null distribution.

```{r}

obs <- freq %>%
  mutate(SINGLETON = ifelse(FRQ <= min, TRUE, FALSE)) %>%
  group_by(LOCUS) %>%
  top_n(-1, FRQ) %>%
  ungroup() %>%
  left_join(contigs) %>%
  filter(!is.na(CHROMOSOME))

summary <- obs %>%
      filter(SINGLETON == TRUE) %>%
      count(CHROMOSOME)

reps <- 1000

sim <- list()

for(i in 1:reps){

    sim[[i]] <- obs %>%
        mutate(SIM = sample(CHROMOSOME, replace = FALSE)) %>%
        ungroup() %>%
        filter(SINGLETON == TRUE) %>%
        count(SIM)
}

null_dist <- ldply(sim, data.frame) %>%
    group_by(SIM) %>%
    summarize(min = min(n),
              max = max(n)) %>%
    ungroup() %>%
    rename(CHROMOSOME = SIM) %>%
    left_join(summary) %>%
    mutate(sign = ifelse(n > min & n < max, "expected", "significant"))

kable(
    null_dist %>%
        filter(sign == "significant") %>%
        select(-sign),
    digits = 2,
    caption = "Chromosomes with significantly higher/lower than expected (outside simulated null distribution) number of loci with observed singletons."
    )

```

Determine the number of singletons individuals in each group carry.

```{r fig.cap="Comparison of number of singletons per individual (individual circles); for individuals grouped by tributary and run type.", fig.height=9, fig.width=8}

# number of loci
nloc <- as.numeric(length(locNames(gen)))

# individuals
Inds <- strata %>%
  select(LIB_ID, SAMPLE_ID, RUN, RUN_LOC)

# extract genotypes
geno <- genind2df(gen)

geno <- bind_cols(Inds, geno) %>%
  select(-pop) %>%
  gather(key = LOCUS, value = GENOTYPE, 5:(nloc+4)) %>%
  separate(GENOTYPE, into = c("ALLELE1", "ALLELE2"), sep = 3) %>%
  mutate(ALLELE1 = as.integer(ALLELE1),
         ALLELE2 = as.integer(ALLELE2)) %>%
  gather(key = GT, value = ALLELE, 6:7)

singletons <- left_join(singletons, geno)

ind_singletons <- count(singletons, SAMPLE_ID) %>%
  filter(!is.na(SAMPLE_ID)) %>%
  left_join(strata) %>%
  mutate(RUN = ordered(RUN, levels = run_levels))

ggplot(ind_singletons, aes(x = RUN_LOC, y = n, color = RUN)) +
  geom_boxplot() +
  scale_fill_manual(values = run_col) +
  scale_color_manual(values = run_col) +
  labs(y = "singletons per indv", x = "") +
  theme_standard +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

mean <- ind_singletons %>%
    group_by(RUN_LOC) %>%
    summarize(mean = mean(n),
              sd = sd(n),
              median = median(n),
              Q1 = quantile(n, 0.25),
              Q3 = quantile(n, 0.75))

kable(
    mean,
    digits = 2,
    caption = "Table S14: Mean, standard deviation, median, 25th and 27th quantile of the number of singletons observer per individual for individuals grouped by run/tributary."
    )

```


## Loci variable in only one group of individuals ("private polymorphisms")

Identify loci that are polymorphic in one set of individuals (i.e. $N(alleles) > 1$) but that locus is *not* variable in *any other* set of individuals (i.e. fixed across all other sets of loci). The polymorphisms must occur in at least one individual of a group (i.e. singletons) but could be variable in multiple individuals, the allele other groups are fixed for may also occur in the group it is variable at, i.e. these are *not* necessarily private alleles, rather they are loci exclusively polymorphic in a single group.


**Identify loci only variable among individuals from the same tributary by run type (private polymorphisms)**

```{r echo=TRUE}

tidy_ar <- read_delim("results/trib_run_rarefied.allelecount", delim = "\t") %>%
  gather(key = GRP, AR, 2:18) %>%
  mutate(GRP = ordered(GRP, levels = trib_runs)) %>%
  rename(N_ALLELES = AR)

pops <- unique(tidy_ar$GRP)

# df for results
results <- setNames(data.frame(matrix(ncol = 2, nrow = 0)), 
                    c("LOCUS", "POLYMORPHIC")) %>%
  mutate(LOCUS = as.character(LOCUS),
         POLYMORPHIC = as.character(POLYMORPHIC))

# loop over to identify loci polymorphic in one pop but fixed in all others
for(p in pops){

# find loci polymorphic in pop
polymorphic <- tidy_ar %>%
  filter(N_ALLELES > 1 & GRP == p)

# find loci fixed in all other pops
fixed <- tidy_ar %>%
  filter(!GRP == p) %>%
  group_by(LOCUS) %>%
  count(N_ALLELES == 1) %>%
  filter(`N_ALLELES == 1` == TRUE) %>%
  filter(n == length(pops)-1) %>%
  mutate(POLYMORPHIC = p) %>%
  select(LOCUS, POLYMORPHIC)

results <- bind_rows(results, fixed)

}

pp <- results %>%
    count(LOCUS) %>%
    filter(n == 1)

results <- results %>%
    filter(LOCUS %in% pp$LOCUS) 

```

Determine differences in number of loci with private polymorphisms among run/tributary groups.

```{r}

tmp <- results %>%
  count(POLYMORPHIC) %>%
  separate(POLYMORPHIC, into = c("RUN", "TRIB"), remove = FALSE) %>%
  mutate(POLYMORPHIC = ordered(POLYMORPHIC, levels = trib_runs),
         RUN = case_when(RUN == "F" ~ "Fall",
                         RUN == "S" ~ "Spring",
                         RUN == "L" ~ "Late-Fall",
                         RUN == "W" ~ "Winter"))

kable(
  results %>%
    count(POLYMORPHIC) %>%
    arrange(desc(n)),
  caption = "Number of loci polymorphic in individuals of the same run type within a tributary that are not variable in individuals of any other group based on rarefied allele counts."
)

```

Compare the distribution of exclusively polymorphic loci across the genome.

```{r}

# chromosome and chromosome number
chrom <- read_delim("data/REF/CHRIST2018/chrom.contigs", delim = " ") %>%
  mutate(CHROM = str_trim(CHROM))

# position of contigs on chromosomes/scaffolds
contigs <- read_delim("data/REF/CHRIST2018/map_intervals.bed", delim = "\t",
                      col_names = c("CHROM", "chromStart", "chromEnd", "LOCUS")) %>%
  left_join(chrom)

polym <- results %>%
    left_join(contigs) %>%
    filter(!is.na(CHROMOSOME)) %>%
    separate(POLYMORPHIC, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE) %>%
    mutate(POLYMORPHIC = ordered(POLYMORPHIC, levels = trib_runs))

n_chrom <- contigs %>%
      filter(!is.na(CHROMOSOME)) %>%
      count(CHROMOSOME) %>%
      rename(total = n)

pattern <- polym %>%
      count(POLYMORPHIC, CHROMOSOME) %>%
      left_join(n_chrom) %>%
      mutate(percent = (n/total)*100)

n <- pattern %>%
      select(CHROMOSOME, total, POLYMORPHIC, n) %>%
      spread(key = POLYMORPHIC, value = n)

frq <- pattern %>%
      select(CHROMOSOME, total, POLYMORPHIC, percent) %>%
      spread(key = POLYMORPHIC, value = percent)

```

Determine the percent of loci on a chromosome that are only polymorphic for a set of individuals from the same tributary of the same run type.

```{r}

# print tables
kable(
      frq,
      digits = 2,
      caption = "Percent loci on a chromosome that are only polymorphic for a set of individuals from the same tributary of the same run type."
      )

```

Generate null distribution to determine if some groups exhibit more/less than the expected number of loci with exclusive polymorphisms for sets of individuals.

```{r}

flagged <- results %>%
    rename(GRP = POLYMORPHIC) %>%
    mutate(POLYMORPHIC = TRUE)

obs <- tidy_ar %>%
   filter(!LOCUS == "mean") %>%
   left_join(flagged) %>%
   mutate(GRP = ordered(GRP, levels = trib_runs),
          POLYMORPHIC = replace_na(POLYMORPHIC, FALSE)) %>%
   left_join(contigs) %>%
   filter(!is.na(CHROMOSOME)) %>%
   select(GRP, LOCUS, POLYMORPHIC, CHROMOSOME)

summary <- pattern %>%
   rename(GRP = POLYMORPHIC)

reps <- 1000

sim <- list()

for(i in 1:reps){

    sim[[i]] <- obs %>%
        group_by(GRP) %>%
        mutate(SIM = sample(CHROMOSOME, replace = FALSE)) %>%
        ungroup() %>%
        filter(POLYMORPHIC == TRUE) %>%
        count(GRP, SIM) %>%
        left_join(n_chrom, by = c("SIM" = "CHROMOSOME")) %>%
        mutate(percent = (n/total)*100)
}

null_dist <- ldply(sim, data.frame) %>%
    group_by(GRP, SIM) %>%
    summarize(min = min(percent),
              max = max(percent)) %>%
    ungroup() %>%
    rename(CHROMOSOME = SIM) %>%
    left_join(summary) %>%
    select(GRP, CHROMOSOME, total, n, percent, min, max) %>%
    mutate(sign = case_when(percent > min & percent < max ~ "expected",
                            percent <= min ~ "lower",
                            percent >= max ~ "higher"))

sign <- null_dist %>%
    filter(!sign == "expected")

# significant group/chromosome combinations
kable(
    sign,
    digits = 4,
    caption = "Chromosomes with significantly higher/lower than expected (outside simulated null distribution) number of private polymorhisms for each run/tributary group"
    )

kable(
      pattern %>%
          group_by(POLYMORPHIC) %>%
          summarize(mean = mean(percent),
                    sd = sd(percent),
                    min = min(percent),
                    max = max(percent)),
      digits = 2,
      caption = "Table S15: Comparison across run/tributary group of the mean +/- sd, minimum, and maximum percent of loci on a chromosome that are only polymorphic for a set of individuals from the same tributary of the same run type."
      )

# group patterns
kable(
    sign %>%
      count(GRP, sign) %>%
      arrange(desc(n)),
    caption = "Table S16: Number of chromosomes with significantly more/less loci with private polymorphisms than expected."
    )


# chromosome patterns
kable(
    sign %>%
      count(CHROMOSOME, sign) %>%
      arrange(desc(n)),
    caption = "Table S17: Number of run/trib groups a chromosome has been flagged as having significantly more/less loci with private polymorphisms than expected."
    )



```

**Identify loci only variable among individuals from the same run type (private polymorphisms)**

For this analysis we will exclude hatchery individuals and combine wild individuals from each run and the subset to 21 individuals (number of individuals in Late Fall run data set) to identify the number of alleles that occur only in individuals of a given run.

```{r echo=TRUE}

# wild populations
wild <- strata %>%
  filter(SOURCE == "WILD")

# subset genind object
gen_wild <- gen[row.names(gen@tab) %in% wild$LIB_ID]

# by tributary within run
setPop(gen_wild) <- ~RUN

# calculate allele counts using rarefaction ----
dat <- genind2hierfstat(gen_wild)

df <- allelic.richness(dat,
                       diploid = TRUE)

df <- as.data.frame(df$Ar) %>%
  rownames_to_column("LOCUS")

write_delim(df, "results/run_rarefied.allelecount", delim = "\t")

# identify private polymorphisms ----
tidy_ar <-df %>%
  gather(key = GRP, AR, 2:5) %>%
  mutate(GRP = ordered(GRP, levels = run_levels)) %>%
  rename(N_ALLELES = AR)

pops <- unique(tidy_ar$GRP)

# df for results
results <- setNames(data.frame(matrix(ncol = 2, nrow = 0)), 
                    c("LOCUS", "POLYMORPHIC")) %>%
  mutate(LOCUS = as.character(LOCUS),
         POLYMORPHIC = as.character(POLYMORPHIC))

# loop over to identify loci polymorphic in one pop but fixed in all others
for(p in pops){

# find loci polymorphic in pop
polymorphic <- tidy_ar %>%
  filter(N_ALLELES > 1 & GRP == p)

# find loci fixed in all other pops
fixed <- tidy_ar %>%
  filter(!GRP == p) %>%
  group_by(LOCUS) %>%
  count(N_ALLELES == 1) %>%
  filter(`N_ALLELES == 1` == TRUE) %>%
  filter(n == length(pops)-1) %>%
  mutate(POLYMORPHIC = p) %>%
  select(LOCUS, POLYMORPHIC)

results <- bind_rows(results, fixed)

}

pp <- results %>%
    count(LOCUS) %>%
    filter(n == 1)

results <- results %>%
    filter(LOCUS %in% pp$LOCUS) 

```

Determine differences in number of loci with private polymorphisms among run/tributary groups.

```{r}

kable(
  results %>%
    count(POLYMORPHIC) %>%
    rename(population = POLYMORPHIC) %>%
    mutate(population = factor(population, levels = run_levels)),
  caption = "Number of loci polymorphic in individuals of the same run type that are not variable in individuals of any other run based on rarefied allele counts."
)

```


## Private alleles

**Private alleles** are alleles that only occur within a given set of individuals; this can be a locus that is only variable in one set of individuals (all other individuals are fixed for the alternate allele(s)) or it could be a locus with multiple alleles, that are variable in other sets of individuals (i.e. heterozygotes & homozygotes occur) but one (or more) of those alleles only exists within a given set of individuals. Not all individuals of the group will have the private allele, i.e. they may be more or less common.

**Comparison of private alleles by tributary within run type**

There is a relationship between sample size and the number of private alleles found making it different to compare levels overall (many private alleles are rare so for smaller sample sizes they might not be recovered); though it is important to note that all run/tributary groups do exhibit private alleles, i.e. harbor unique genetic material. 

```{r fig.cap="Comparison of sample size and number of private alleles detected in each trib/run population."}

# determine private alleles for unequal sample sizes
alleles_private <- poppr::private_alleles(gen,
                                            alleles ~ RUN_LOC,
                                            report = "data.frame")
# count no private alleles per population
all_ind <- alleles_private %>%
    filter(count > 0) %>%
    count(population) %>%
    rename(priv_alleles_all = n) %>%
  left_join(run_counts, by = c("population" = "RUN_LOC"))

ggplot(all_ind, aes(x = n, y = priv_alleles_all)) +
  stat_smooth(method = "lm") +
  geom_point() +
  theme_standard

```

To account for this, we subsampled down to 15 individuals 100 times to determine the number of private alleles occurring in each subset of individuals.

```{r eval=FALSE, echo=TRUE}

# unset the seed to get individually different reps
set.seed(NULL)

# list for results
priv_allele_counts <- list()

# number of individuals to subset
n <- 20

# feather river spring individuals

for(i in 1:100){

  # draw up to n individuals from each population
  sample_ind <- strata %>%
    group_by(RUN_LOC) %>%
    slice_sample(n = n)
  
  # subset genind object
  gen_subset <- gen[row.names(gen@tab) %in% sample_ind$LIB_ID]
  
  # identify private alleles
  alleles_private <- poppr::private_alleles(gen_subset,
                                            alleles ~ RUN_LOC,
                                            report = "data.frame")
  # count no private alleles per population
  priv_allele_counts[[i]] <- alleles_private %>%
    filter(count > 0) %>%
    count(population) %>%
    mutate(rep = i)
  
}

results <- ldply(priv_allele_counts, data.frame)

write_delim(results, "results/priv-alleles_15ind-100reps.txt",
            delim = "\t")

```

Calculate the mean number of private alleles across all bootstraps.

```{r fig.cap="Compariso of sample size and number of private alleles detected in each trib/run population after adjusting for sampling size by bootstrapping to 15 individuals."}

read_delim("results/priv-alleles_15ind-100reps.txt", 
             delim = "\t") %>%
    group_by(population) %>%
    summarize(mean = mean(n)) %>%
  left_join(run_counts, by = c("population" = "RUN_LOC")) %>%
  ggplot(aes(x = n, y = mean)) +
  stat_smooth(method = "lm") +
  geom_point() +
  labs(x = "n individuals", y = "mean private alleles") +
  theme_standard


kable(
 read_delim("results/priv-alleles_15ind-100reps.txt", 
             delim = "\t") %>%
    group_by(population) %>%
    summarize(mean = mean(n),
              sd = sd(n)) %>%
   mutate(population = factor(population, levels = trib_runs)) %>%
   arrange(population),
  caption = "Number of private alleles occurring in each set of individuals grouped by run type within tributaries. All populations except for S_FRH were subsampled down to 15 individuals."
)

```

Populations with high standard deviations are either hatchery individuals or have large number of private polymorphisms (which set of individuals that you pull out can have a larger impact on number of private alleles depending on whether you happen to pull a set with a large number of private polymorphisms or not).

Compare the distribution of loci with private alleles across the genome.

```{r}

# chromosome and chromosome number
chrom <- read_delim("data/REF/CHRIST2018/chrom.contigs", delim = " ") %>%
  mutate(CHROM = str_trim(CHROM))

# position of contigs on chromosomes/scaffolds
contigs <- read_delim("data/REF/CHRIST2018/map_intervals.bed", delim = "\t",
                      col_names = c("CHROM", "chromStart", "chromEnd", "LOCUS")) %>%
  left_join(chrom)

alleles_private <- poppr::private_alleles(gen,
                                          alleles ~ RUN_LOC,
                                          report = "data.frame")

PA <- alleles_private %>%
    filter(count > 0) %>%
    separate(allele, into = c("LOCUS", "ALLELE"), sep = -4) %>%
    left_join(contigs) %>%
    filter(!is.na(CHROMOSOME)) %>%
    separate(population, into = c("RUN", "TRIBUTARY"), sep = "_", remove = FALSE) %>%
    mutate(population = ordered(population, levels = trib_runs))

n_chrom <- contigs %>%
      filter(!is.na(CHROMOSOME)) %>%
      count(CHROMOSOME) %>%
      rename(total = n)

pattern <- PA %>%
      count(population, CHROMOSOME) %>%
      left_join(n_chrom) %>%
      mutate(percent = (n/total)*100)

n <- pattern %>%
      select(CHROMOSOME, total, population, n) %>%
      spread(key = population, value = n)

```

Determine the % loci of a given chromosome that are only polymorphic for a set of individuals from the same tributary of the same run type.

```{r}

frq <- pattern %>%
      select(CHROMOSOME, total, population, percent) %>%
      spread(key = population, value = percent)

kable(
     frq,
     digits = 2
     )

```

Compare the mean proportion of loci per chromosome that are private polymorphisms across tributaries.

```{r}

by_loc <- pattern %>%
    group_by(population) %>%
    summarize(mean = mean(percent),
              sd = sd(percent),
              min = min(percent),
              max = max(percent))

kable(
      by_loc,
      digits = 2,
      caption = "Table S18: Comparison across run/tributary group of the mean +/- sd, minimum, and maximum percent of loci on a chromosome that are only polymorphic for a set of individuals from the same tributary of the same run type."
      )

```

Generate a random null distribution to determine if loci with private alleles are non-randomly distributed across chromosomes.

```{r}

flagged <- alleles_private %>%
    mutate(PRIVATE = ifelse(count > 0, TRUE, FALSE)) %>%
    separate(allele, into = c("LOCUS", "ALLELE"), sep = -4) %>%
    select(population, LOCUS, PRIVATE) %>%
    rename(GRP = population) 
  
obs <- flagged %>%
    left_join(contigs) %>%
    mutate(GRP = ordered(GRP, levels = trib_runs)) %>%
    filter(!is.na(CHROMOSOME)) %>%
    select(GRP, LOCUS, PRIVATE, CHROMOSOME)

summary <- pattern %>%
   rename(GRP = population)

reps <- 1000

sim <- list()

for(i in 1:reps){

    sim[[i]] <- obs %>%
        group_by(GRP) %>%
        mutate(SIM = sample(CHROMOSOME, replace = FALSE)) %>%
        ungroup() %>%
        filter(PRIVATE == TRUE) %>%
        count(GRP, SIM) %>%
        left_join(n_chrom, by = c("SIM" = "CHROMOSOME")) %>%
        mutate(percent = (n/total)*100)

}

null_dist <- ldply(sim, data.frame) %>%
    group_by(GRP, SIM) %>%
    summarize(min = min(percent),
              max = max(percent)) %>%
    ungroup() %>%
    rename(CHROMOSOME = SIM) %>%
    left_join(summary) %>%
    select(GRP, CHROMOSOME, total, n, percent, min, max) %>%
    mutate(sign = case_when(percent > min & percent < max ~ "expected",
                            percent <= min ~ "lower",
                            percent >= max ~ "higher"))

sign <- null_dist %>%
    filter(!sign == "expected")

# significant group/chromosome combinations
kable(
    sign %>%
      group_by(sign) %>%
      arrange(desc(CHROMOSOME)),
    digits = 4,
    caption = "Table S19: Chromosomes with significantly higher/lower than expected (outside simulated null distribution) number of fixed loci for each run/tributary group"
    )

# chromosome patterns
kable(
    sign %>%
      count(CHROMOSOME, sign) %>%
      arrange(desc(n)),
    caption = "Table S20: Number of run/trib groups a chromosome has been flagged as having significantly more/less loci with exclusive polymorphisms than expected."
    )

# group patterns
kable(
    sign %>%
      count(GRP, sign) %>%
      arrange(desc(n)),
    caption = "Number of chromosomes with significantly more/less loci with exclusive polymorphisms than expected."
    )

```


**Comparison of private alleles among runs**

For this analysis we will exclude hatchery individuals and combine wild individuals from each run and the subset to 21 individuals (number of individuals in Late Fall run data set) to identify the number of alleles that occur only in individuals of a given run.

```{r eval=FALSE, echo=TRUE}

# unset the seed to get individually different reps
set.seed(NULL)

# list for results
priv_allele_counts <- list()

# number of individuals to subset
n <- 21

# wild populations
wild <- strata %>%
  filter(SOURCE == "WILD")

for(i in 1:100){

  # draw up to n individuals from each population
  sample_ind <- wild %>%
    group_by(RUN) %>%
    slice_sample(n = n)
  
  # subset genind object
  gen_subset <- gen[row.names(gen@tab) %in% sample_ind$LIB_ID]
  
  # identify private alleles
  alleles_private <- poppr::private_alleles(gen_subset,
                                            alleles ~ RUN,
                                            report = "data.frame")
  
  # count no private alleles per population
  priv_allele_counts[[i]] <- alleles_private %>%
    filter(count > 0) %>%
    count(population) %>%
    mutate(rep = i)
  
}

results <- ldply(priv_allele_counts, data.frame)

write_delim(results, "results/priv-alleles_wild_ind21_reps100.txt",
            delim = "\t")

```

Calculate the mean number of private alleles across all bootstraps.

```{r fig.cap="Compariso of sample size and number of private alleles detected in each trib/run population after adjusting for sampling size by bootstrapping to 15 individuals."}

kable(
 read_delim("results/priv-alleles_wild_ind21_reps100.txt", 
             delim = "\t") %>%
    group_by(population) %>%
    summarize(mean = mean(n),
              sd = sd(n)) %>%
   mutate(population = factor(population, levels = run_levels)) %>%
   arrange(population),
  caption = "Number of private alleles occurring in each set of individuals grouped by run type within tributaries. All populations except for S_FRH were subsampled down to 15 individuals."
)

```





### Session Information

`r margin_note("Package versions used for this analysis (R 4.0.5).")`

```{r}

subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion))

```
